{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pygame\n",
    "import load\n",
    "from models import DynamicTopologyModel\n",
    "import load_topology_dataset\n",
    "from load_topology_dataset import MAX_CELL_COUNT, MIN_CELL_COUNT, IMAGE_SIZE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "EXPERIMENT=1\n",
    "writer = SummaryWriter('runs/experiment_{}/'.format(EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameters(writer, model, batch_idx):\n",
    "    for k, v in model.state_dict().items():\n",
    "        shape = v.shape\n",
    "        # Don't do this for single weights or biases\n",
    "        if np.any(np.array(shape) > 1):\n",
    "            mean = torch.mean(v)\n",
    "            std_dev = torch.std(v)\n",
    "            maximum = torch.max(v)\n",
    "            minimum = torch.min(v)\n",
    "            writer.add_scalars(\"{}_{} \".format(k, shape), {\"mean\": mean,\n",
    "                                                                    \"std_dev\": std_dev,\n",
    "                                                                    \"max\": maximum,\n",
    "                                                                    \"min\": minimum}, batch_idx)\n",
    "            writer.add_histogram(\"{}_{}\".format(k, shape), v, batch_idx)\n",
    "            \n",
    "        else:\n",
    "            writer.add_scalar(\"{}_{}\".format(k, shape), v.data, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameters_update(last_parameters_np ,parameters_np):\n",
    "    for last_param, param in zip(last_parameters_np, parameters_np):\n",
    "        diff = param - last_param\n",
    "        #print(last_parameters.max())\n",
    "        print(diff.max())\n",
    "        #print(not np.all(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_present_input,\n",
    "                  reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target,\n",
    "                  neighbourhood_cell_present_target):\n",
    "    print(\"reference_cell_input\") \n",
    "    print(reference_cell_input)\n",
    "    print(\"reference_cell_present_input\") \n",
    "    print(reference_cell_present_input)\n",
    "    print(\"neighbourhood_cell_rel_input\") \n",
    "    print(neighbourhood_cell_rel_input)\n",
    "    print(\"neighbourhood_cell_load_input\") \n",
    "    print(neighbourhood_cell_load_input)\n",
    "    print(\"neighbourhood_cell_present_input\") \n",
    "    print(neighbourhood_cell_present_input)\n",
    "    print(\"reference_cell_target\") \n",
    "    print(reference_cell_target)\n",
    "    print(\"reference_cell_present_target\") \n",
    "    print(reference_cell_present_target)\n",
    "    print(\"neighbourhood_cell_rel_target\") \n",
    "    print(neighbourhood_cell_rel_target)\n",
    "    print(\"neighbourhood_cell_present_target\") \n",
    "    print(neighbourhood_cell_present_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00086665154\n",
      "0.00086659193\n",
      "0.0009960532\n",
      "0.000990957\n",
      "0.0009812862\n",
      "0.00097593665\n",
      "0.0009995038\n",
      "0.0009986311\n",
      "0.0009999909\n",
      "0.0\n",
      "0.000999324\n",
      "0.000999324\n",
      "0.0009998903\n",
      "0.0\n",
      "0.000999935\n",
      "0.000999935\n",
      "0.0\n",
      "0.0\n",
      "0.0009995699\n",
      "0.0009998083\n",
      "0.0009999312\n",
      "0.0009999312\n",
      "0.0009999722\n",
      "0.0009995997\n",
      "0.0009998549\n",
      "0.0009998567\n",
      "0.0009999387\n",
      "0.0009997264\n",
      "0.0009999741\n",
      "0.0009999732\n",
      "0.0009999871\n",
      "0.001000002\n",
      "graph(%0 : Int(1)\n",
      "      %1 : Int(1)\n",
      "      %2 : Float(1, 2, 1)\n",
      "      %3 : Float(1, 2, 1)\n",
      "      %4 : Float(1, 2, 8, 2)\n",
      "      %5 : Float(1, 2, 8, 1)\n",
      "      %6 : Float(1, 2, 1)\n",
      "      %7 : Float(1, 2, 1)\n",
      "      %8 : Float(1, 2, 8, 2)\n",
      "      %9 : Float(32, 2)\n",
      "      %10 : Float(32)\n",
      "      %11 : Float(32, 1)\n",
      "      %12 : Float(32)\n",
      "      %13 : Float(1, 32)\n",
      "      %14 : Float(1)\n",
      "      %15 : Float(1, 32)\n",
      "      %16 : Float(1)\n",
      "      %17 : Float(128, 3)\n",
      "      %18 : Float(128, 32)\n",
      "      %19 : Float(128)\n",
      "      %20 : Float(128)\n",
      "      %21 : Float(128, 32)\n",
      "      %22 : Float(128, 32)\n",
      "      %23 : Float(128)\n",
      "      %24 : Float(128)\n",
      "      %25 : Float(1, 32)\n",
      "      %26 : Float(1)\n",
      "      %27 : Float(32, 2)\n",
      "      %28 : Float(32)\n",
      "      %29 : Float(16, 32)\n",
      "      %30 : Float(16)\n",
      "      %31 : Float(128, 18)\n",
      "      %32 : Float(128, 32)\n",
      "      %33 : Float(128)\n",
      "      %34 : Float(128)\n",
      "      %35 : Float(128, 32)\n",
      "      %36 : Float(128, 32)\n",
      "      %37 : Float(128)\n",
      "      %38 : Float(128)\n",
      "      %39 : Float(1, 32)\n",
      "      %40 : Float(1)) {\n",
      "  %41 : Long() = onnx::Constant[value={0}](), scope: DynamicTopologyModel\n",
      "  %42 : Tensor = onnx::Shape(%2), scope: DynamicTopologyModel\n",
      "  %43 : Long() = onnx::Gather[axis=0](%42, %41), scope: DynamicTopologyModel\n",
      "  %44 : Long() = onnx::Constant[value={2}](), scope: DynamicTopologyModel\n",
      "  %45 : Long() = onnx::Constant[value={1}](), scope: DynamicTopologyModel\n",
      "  %46 : int[] = prim::ListConstruct(%43, %44, %45), scope: DynamicTopologyModel\n",
      "  %47 : Float(1, 2, 1) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=0](%46), scope: DynamicTopologyModel\n",
      "  return (%47);\n",
      "}\n",
      "\n",
      "522.7555490501531 Examples/sec\n",
      "loss: 0.011078844778239727\n",
      "output: tensor([[[-0.1080],\n",
      "         [-0.1024]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "89.2416512204242 Examples/sec\n",
      "loss: 0.8266591429710388\n",
      "output: tensor([[[1.5955],\n",
      "         [1.9438]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.4721],\n",
      "         [1.0032]]])\n",
      "86.20310658755521 Examples/sec\n",
      "loss: 1.596735954284668\n",
      "output: tensor([[[1.7964],\n",
      "         [1.1045]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.3739],\n",
      "         [1.9441]]])\n",
      "97.55459887012265 Examples/sec\n",
      "loss: 23.42241668701172\n",
      "output: tensor([[[4.5592],\n",
      "         [4.6760]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[11.0015],\n",
      "         [ 6.9873]]])\n",
      "96.46280538918401 Examples/sec\n",
      "loss: 4.119539737701416\n",
      "output: tensor([[[3.3307],\n",
      "         [2.4107]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.4215],\n",
      "         [4.3773]]])\n",
      "96.25157852588782 Examples/sec\n",
      "loss: 4.609286785125732\n",
      "output: tensor([[[2.7958],\n",
      "         [1.1841]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "95.69139906566917 Examples/sec\n",
      "loss: 13.534610748291016\n",
      "output: tensor([[[4.6677],\n",
      "         [2.2983]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.62447802772307 Examples/sec\n",
      "loss: 0.6916078329086304\n",
      "output: tensor([[[1.1550],\n",
      "         [0.2220]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.67449407820386 Examples/sec\n",
      "loss: 6.8532891273498535\n",
      "output: tensor([[[ 3.6889],\n",
      "         [-0.3135]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.71170530782852 Examples/sec\n",
      "loss: 2.594886302947998\n",
      "output: tensor([[[5.6399],\n",
      "         [5.1258]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[7.9180],\n",
      "         [5.1308]]])\n",
      "91.6184677177748 Examples/sec\n",
      "loss: 0.0817423090338707\n",
      "output: tensor([[[-0.4042],\n",
      "         [-0.0110]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.12380746401365 Examples/sec\n",
      "loss: 0.02656986005604267\n",
      "output: tensor([[[1.4887],\n",
      "         [1.3337]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.5206],\n",
      "         [1.1054]]])\n",
      "94.06373194093926 Examples/sec\n",
      "loss: 0.5165619850158691\n",
      "output: tensor([[[4.3750],\n",
      "         [2.2584]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.5243],\n",
      "         [1.7022]]])\n",
      "97.4232523973427 Examples/sec\n",
      "loss: 1.1672124862670898\n",
      "output: tensor([[[7.1255],\n",
      "         [4.9937]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[7.6885],\n",
      "         [3.5734]]])\n",
      "97.54993581214224 Examples/sec\n",
      "loss: 0.05107424035668373\n",
      "output: tensor([[[-0.2633],\n",
      "         [-0.1811]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.85128267389561 Examples/sec\n",
      "loss: 0.12275631725788116\n",
      "output: tensor([[[1.0570],\n",
      "         [1.0495]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.9384],\n",
      "         [0.5684]]])\n",
      "92.2601995957158 Examples/sec\n",
      "loss: 1.9683269262313843\n",
      "output: tensor([[[8.1777],\n",
      "         [6.4098]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[9.1465],\n",
      "         [4.6783]]])\n",
      "94.37755173305499 Examples/sec\n",
      "loss: 0.03136742487549782\n",
      "output: tensor([[[3.4165],\n",
      "         [3.1017]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.1779],\n",
      "         [3.1779]]])\n",
      "95.12792803762501 Examples/sec\n",
      "loss: 0.05796373263001442\n",
      "output: tensor([[[4.8300],\n",
      "         [3.1561]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.6015],\n",
      "         [2.9038]]])\n",
      "94.8743199883115 Examples/sec\n",
      "loss: 3.508742884150706e-05\n",
      "output: tensor([[[1.6613],\n",
      "         [1.3256]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.6599],\n",
      "         [1.3174]]])\n",
      "95.6032998434974 Examples/sec\n",
      "loss: 0.0010140500962734222\n",
      "output: tensor([[[0.0130],\n",
      "         [0.0431]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "95.67629265847104 Examples/sec\n",
      "loss: 0.0832376703619957\n",
      "output: tensor([[[0.2592],\n",
      "         [0.3151]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.64803236205523 Examples/sec\n",
      "loss: 0.00022106728283688426\n",
      "output: tensor([[[0.5180],\n",
      "         [0.4541]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.5389],\n",
      "         [0.4518]]])\n",
      "96.55874295966066 Examples/sec\n",
      "loss: 0.7391460537910461\n",
      "output: tensor([[[5.2304],\n",
      "         [4.0141]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.4237],\n",
      "         [4.2475]]])\n",
      "93.13709967346134 Examples/sec\n",
      "loss: 0.022544510662555695\n",
      "output: tensor([[[3.1829],\n",
      "         [2.5130]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.3233],\n",
      "         [2.6723]]])\n",
      "94.80515171194403 Examples/sec\n",
      "loss: 0.0052158827893435955\n",
      "output: tensor([[[0.0252],\n",
      "         [0.0990]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.08444078560508 Examples/sec\n",
      "loss: 0.023936055600643158\n",
      "output: tensor([[[2.2139],\n",
      "         [1.5046]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.2075],\n",
      "         [1.7233]]])\n",
      "94.71706119479889 Examples/sec\n",
      "loss: 0.16043761372566223\n",
      "output: tensor([[[3.0949],\n",
      "         [1.7508]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.5304],\n",
      "         [2.1130]]])\n",
      "93.91487930998859 Examples/sec\n",
      "loss: 0.004587232135236263\n",
      "output: tensor([[[-0.0637],\n",
      "         [-0.0715]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "95.04339206064529 Examples/sec\n",
      "loss: 0.09782901406288147\n",
      "output: tensor([[[4.8751],\n",
      "         [3.5802]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.5018],\n",
      "         [3.3430]]])\n",
      "94.76445347444393 Examples/sec\n",
      "loss: 0.007218404673039913\n",
      "output: tensor([[[ 0.1006],\n",
      "         [-0.0657]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.7440725739596 Examples/sec\n",
      "loss: 0.006772069726139307\n",
      "output: tensor([[[0.1163],\n",
      "         [0.0048]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "95.11200389578767 Examples/sec\n",
      "loss: 0.028672629967331886\n",
      "output: tensor([[[5.3456],\n",
      "         [3.7779]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.2900],\n",
      "         [3.5450]]])\n",
      "95.13869795080758 Examples/sec\n",
      "loss: 0.38438862562179565\n",
      "output: tensor([[[4.8824],\n",
      "         [3.0538]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.0660],\n",
      "         [2.7339]]])\n",
      "94.7110507906952 Examples/sec\n",
      "loss: 0.0073605929501354694\n",
      "output: tensor([[[-0.1212],\n",
      "         [ 0.0045]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.53582907922102 Examples/sec\n",
      "loss: 0.04907697066664696\n",
      "output: tensor([[[2.5089],\n",
      "         [1.1520]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.6296],\n",
      "         [1.4412]]])\n",
      "96.1007135477981 Examples/sec\n",
      "loss: 0.024518601596355438\n",
      "output: tensor([[[3.2980],\n",
      "         [1.3330]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.4623],\n",
      "         [1.4815]]])\n",
      "94.96946731625782 Examples/sec\n",
      "loss: 0.004275978542864323\n",
      "output: tensor([[[4.0030],\n",
      "         [2.8607]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.9131],\n",
      "         [2.8388]]])\n",
      "95.03661760876464 Examples/sec\n",
      "loss: 0.01593524031341076\n",
      "output: tensor([[[0.5799],\n",
      "         [0.3532]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.7263],\n",
      "         [0.4555]]])\n",
      "92.25058210117307 Examples/sec\n",
      "loss: 0.028844131156802177\n",
      "output: tensor([[[2.3333],\n",
      "         [2.0789]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.3186],\n",
      "         [2.3186]]])\n",
      "94.55299127843207 Examples/sec\n",
      "loss: 0.012934459373354912\n",
      "output: tensor([[[-0.1219],\n",
      "         [-0.1049]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.95089437200059 Examples/sec\n",
      "loss: 0.31347209215164185\n",
      "output: tensor([[[3.9433],\n",
      "         [2.9812]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.4260],\n",
      "         [3.6089]]])\n",
      "96.92909249167865 Examples/sec\n",
      "loss: 0.019528087228536606\n",
      "output: tensor([[[3.6430],\n",
      "         [2.6085]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.5736],\n",
      "         [2.4234]]])\n",
      "97.01024137118156 Examples/sec\n",
      "loss: 0.003566068597137928\n",
      "output: tensor([[[1.9910],\n",
      "         [1.5199]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.0734],\n",
      "         [1.5012]]])\n",
      "97.68257850748834 Examples/sec\n",
      "loss: 0.0002649664820637554\n",
      "output: tensor([[[-0.0079],\n",
      "         [-0.0216]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.24495323003974 Examples/sec\n",
      "loss: 0.05886072665452957\n",
      "output: tensor([[[3.9156],\n",
      "         [2.9603]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.5901],\n",
      "         [2.8519]]])\n",
      "97.3125201315276 Examples/sec\n",
      "loss: 0.02093784511089325\n",
      "output: tensor([[[6.0675],\n",
      "         [4.6229]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.9817],\n",
      "         [4.8087]]])\n",
      "97.73537365699379 Examples/sec\n",
      "loss: 0.03363427147269249\n",
      "output: tensor([[[0.9538],\n",
      "         [0.8578]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.8052],\n",
      "         [0.6452]]])\n",
      "97.30825894116937 Examples/sec\n",
      "loss: 0.008559553883969784\n",
      "output: tensor([[[0.1281],\n",
      "         [0.0267]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.57506449711762 Examples/sec\n",
      "loss: 0.021002039313316345\n",
      "output: tensor([[[2.2690],\n",
      "         [1.4641]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.3314],\n",
      "         [1.6593]]])\n",
      "97.72744597138148 Examples/sec\n",
      "loss: 0.27990326285362244\n",
      "output: tensor([[[4.8156],\n",
      "         [3.5802]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.4319],\n",
      "         [4.0044]]])\n",
      "97.50580159519492 Examples/sec\n",
      "loss: 2.4820988178253174\n",
      "output: tensor([[[1.8589],\n",
      "         [1.2282]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.6631169379097 Examples/sec\n",
      "loss: 0.5698667764663696\n",
      "output: tensor([[[10.4504],\n",
      "         [ 8.0145]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[10.3591],\n",
      "         [ 6.9509]]])\n",
      "96.9542783014386 Examples/sec\n",
      "loss: 0.5428731441497803\n",
      "output: tensor([[[8.3513],\n",
      "         [6.3132]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[7.5887],\n",
      "         [5.6031]]])\n",
      "97.2519516035388 Examples/sec\n",
      "loss: 0.0043765585869550705\n",
      "output: tensor([[[0.0891],\n",
      "         [0.0284]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.26320785731099 Examples/sec\n",
      "loss: 0.20958071947097778\n",
      "output: tensor([[[4.8218],\n",
      "         [2.9301]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.6544],\n",
      "         [2.3047]]])\n",
      "97.9915648860946 Examples/sec\n",
      "loss: 0.2594793140888214\n",
      "output: tensor([[[8.6766],\n",
      "         [4.8224]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[8.9642],\n",
      "         [4.1619]]])\n",
      "97.66187700267886 Examples/sec\n",
      "loss: 0.7553211450576782\n",
      "output: tensor([[[3.6595],\n",
      "         [1.2064]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.4244],\n",
      "         [0.0000]]])\n",
      "97.31053152958532 Examples/sec\n",
      "loss: 3.049954652786255\n",
      "output: tensor([[[4.8475],\n",
      "         [4.3506]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.3277],\n",
      "         [6.3277]]])\n",
      "97.83883790941884 Examples/sec\n",
      "loss: 0.0024720127694308758\n",
      "output: tensor([[[0.0555],\n",
      "         [0.0432]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "98.05623132641645 Examples/sec\n",
      "loss: 0.014123224653303623\n",
      "output: tensor([[[4.1175],\n",
      "         [3.2215]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.2852],\n",
      "         [3.2331]]])\n",
      "98.03844675728033 Examples/sec\n",
      "loss: 0.04774269461631775\n",
      "output: tensor([[[1.2389],\n",
      "         [1.3714]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.0969],\n",
      "         [1.0969]]])\n",
      "97.99886321318672 Examples/sec\n",
      "loss: 0.00415588216856122\n",
      "output: tensor([[[-0.0828],\n",
      "         [-0.0381]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.51047090354068 Examples/sec\n",
      "loss: 0.004664202220737934\n",
      "output: tensor([[[1.8054],\n",
      "         [1.6961]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.7917],\n",
      "         [1.7917]]])\n",
      "97.88519046010933 Examples/sec\n",
      "loss: 0.09058389812707901\n",
      "output: tensor([[[5.6310],\n",
      "         [4.0845]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.8898],\n",
      "         [4.4224]]])\n",
      "97.38331044825539 Examples/sec\n",
      "loss: 0.16694730520248413\n",
      "output: tensor([[[6.1701],\n",
      "         [4.1240]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.7649],\n",
      "         [3.7121]]])\n",
      "97.34396978443178 Examples/sec\n",
      "loss: 0.026142733171582222\n",
      "output: tensor([[[4.4152],\n",
      "         [2.4292]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.4653],\n",
      "         [2.6523]]])\n",
      "97.77206788901307 Examples/sec\n",
      "loss: 0.11930876225233078\n",
      "output: tensor([[[1.4198],\n",
      "         [1.1566]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.7951],\n",
      "         [1.4692]]])\n",
      "90.56650252997525 Examples/sec\n",
      "loss: 0.03836354613304138\n",
      "output: tensor([[[1.3169],\n",
      "         [0.5579]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.5771],\n",
      "         [0.6529]]])\n",
      "96.1486689178275 Examples/sec\n",
      "loss: 0.00099138671066612\n",
      "output: tensor([[[-0.0361],\n",
      "         [-0.0261]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "92.14169549933888 Examples/sec\n",
      "loss: 0.0014081831322982907\n",
      "output: tensor([[[0.7725],\n",
      "         [0.7202]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.8164],\n",
      "         [0.6904]]])\n",
      "96.18362608422991 Examples/sec\n",
      "loss: 1.0762470960617065\n",
      "output: tensor([[[11.1141],\n",
      "         [ 5.2205]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[12.3370],\n",
      "         [ 6.0310]]])\n",
      "96.77375650561578 Examples/sec\n",
      "loss: 0.0017636147094890475\n",
      "output: tensor([[[-0.0575],\n",
      "         [-0.0147]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.87538144681444 Examples/sec\n",
      "loss: 0.010873193852603436\n",
      "output: tensor([[[3.3979],\n",
      "         [2.3043]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.4603],\n",
      "         [2.4380]]])\n",
      "97.37401749616346 Examples/sec\n",
      "loss: 0.0033799484372138977\n",
      "output: tensor([[[-0.0663],\n",
      "         [-0.0487]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.00506560452587 Examples/sec\n",
      "loss: 0.022422419860959053\n",
      "output: tensor([[[4.0957],\n",
      "         [3.3357]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.9000],\n",
      "         [3.2548]]])\n",
      "96.82557357049143 Examples/sec\n",
      "loss: 0.03561907634139061\n",
      "output: tensor([[[2.1287],\n",
      "         [2.1715]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.9626],\n",
      "         [1.9626]]])\n",
      "97.22802889617019 Examples/sec\n",
      "loss: 0.0008497608359903097\n",
      "output: tensor([[[0.0377],\n",
      "         [0.0166]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.21177195673687 Examples/sec\n",
      "loss: 0.028587423264980316\n",
      "output: tensor([[[4.3910],\n",
      "         [3.4740]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.1558],\n",
      "         [3.4308]]])\n",
      "96.54252263680799 Examples/sec\n",
      "loss: 0.008259430527687073\n",
      "output: tensor([[[3.3601],\n",
      "         [2.4505]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.2620],\n",
      "         [2.3675]]])\n",
      "93.71166607159759 Examples/sec\n",
      "loss: 0.006455909460783005\n",
      "output: tensor([[[-0.0841],\n",
      "         [-0.0764]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "88.73059351006692 Examples/sec\n",
      "loss: 0.12771226465702057\n",
      "output: tensor([[[3.0348],\n",
      "         [2.1472]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.4181],\n",
      "         [2.4767]]])\n",
      "97.1002939225897 Examples/sec\n",
      "loss: 0.02081620879471302\n",
      "output: tensor([[[1.3259],\n",
      "         [0.9146]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.2072],\n",
      "         [0.7487]]])\n",
      "93.6638292770651 Examples/sec\n",
      "loss: 0.3351050913333893\n",
      "output: tensor([[[6.0773],\n",
      "         [5.6320]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.3890],\n",
      "         [6.3890]]])\n",
      "97.86871303621045 Examples/sec\n",
      "loss: 0.08385711908340454\n",
      "output: tensor([[[6.6286],\n",
      "         [4.9988]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.9107],\n",
      "         [5.2958]]])\n",
      "96.94591290573076 Examples/sec\n",
      "loss: 0.006302169989794493\n",
      "output: tensor([[[5.1612],\n",
      "         [4.1583]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.1191],\n",
      "         [4.0542]]])\n",
      "97.06589221026803 Examples/sec\n",
      "loss: 0.03663761913776398\n",
      "output: tensor([[[5.3131],\n",
      "         [2.9849]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.5032],\n",
      "         [3.1775]]])\n",
      "97.13009702325392 Examples/sec\n",
      "loss: 0.057396892458200455\n",
      "output: tensor([[[3.3145],\n",
      "         [2.7007]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.5257],\n",
      "         [2.9656]]])\n",
      "97.2480740018944 Examples/sec\n",
      "loss: 0.0015845930902287364\n",
      "output: tensor([[[0.0430],\n",
      "         [0.0364]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.33875834679854 Examples/sec\n",
      "loss: 0.03023805283010006\n",
      "output: tensor([[[6.0046],\n",
      "         [2.6453]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.0667],\n",
      "         [2.4073]]])\n",
      "94.88314192240837 Examples/sec\n",
      "loss: 0.030750317499041557\n",
      "output: tensor([[[3.7750],\n",
      "         [3.7445]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.5851],\n",
      "         [3.5851]]])\n",
      "97.28222643994718 Examples/sec\n",
      "loss: 0.003027702681720257\n",
      "output: tensor([[[1.4347],\n",
      "         [0.9873]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.4783],\n",
      "         [1.0518]]])\n",
      "97.2961402621158 Examples/sec\n",
      "loss: 0.008550049737095833\n",
      "output: tensor([[[0.8666],\n",
      "         [0.6461]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.7647],\n",
      "         [0.5642]]])\n",
      "91.52455191867494 Examples/sec\n",
      "loss: 0.007851061411201954\n",
      "output: tensor([[[1.0263],\n",
      "         [0.3273]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.0620],\n",
      "         [0.4475]]])\n",
      "94.8289759418888 Examples/sec\n",
      "loss: 0.016786916181445122\n",
      "output: tensor([[[1.5750],\n",
      "         [1.0432]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.7059],\n",
      "         [1.1714]]])\n",
      "96.603516947638 Examples/sec\n",
      "loss: 0.04464693367481232\n",
      "output: tensor([[[8.3880],\n",
      "         [5.2852]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[8.1969],\n",
      "         [5.5149]]])\n",
      "97.19570939260457 Examples/sec\n",
      "loss: 0.012930319644510746\n",
      "output: tensor([[[4.0681],\n",
      "         [2.4423]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.9336],\n",
      "         [2.3541]]])\n",
      "93.58800501257355 Examples/sec\n",
      "loss: 0.006080134771764278\n",
      "output: tensor([[[3.9251],\n",
      "         [3.1117]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.8239],\n",
      "         [3.0679]]])\n",
      "97.41622934897707 Examples/sec\n",
      "loss: 0.015641193836927414\n",
      "output: tensor([[[1.8134],\n",
      "         [1.8750]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.7230],\n",
      "         [1.7230]]])\n",
      "97.0069476375898 Examples/sec\n",
      "loss: 0.005127410404384136\n",
      "output: tensor([[[6.3524],\n",
      "         [6.2536]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.2512],\n",
      "         [6.2512]]])\n",
      "89.90558115866716 Examples/sec\n",
      "loss: 0.01068031508475542\n",
      "output: tensor([[[-0.1331],\n",
      "         [-0.0603]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.60724998768258 Examples/sec\n",
      "loss: 0.0201556496322155\n",
      "output: tensor([[[5.5120],\n",
      "         [4.6124]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.6308],\n",
      "         [4.4505]]])\n",
      "97.3177287599191 Examples/sec\n",
      "loss: 0.02933003567159176\n",
      "output: tensor([[[3.3662],\n",
      "         [3.2821]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.4902],\n",
      "         [3.4902]]])\n",
      "92.44468110282807 Examples/sec\n",
      "loss: 0.2788979411125183\n",
      "output: tensor([[[11.7356],\n",
      "         [12.1290]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[12.4224],\n",
      "         [12.4224]]])\n",
      "94.73859726243349 Examples/sec\n",
      "loss: 1.4378693776961882e-05\n",
      "output: tensor([[[2.1221],\n",
      "         [2.1165]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.1167],\n",
      "         [2.1167]]])\n",
      "93.79076967519319 Examples/sec\n",
      "loss: 0.0018275555921718478\n",
      "output: tensor([[[6.2223],\n",
      "         [4.1397]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.1962],\n",
      "         [4.0851]]])\n",
      "94.20489187162512 Examples/sec\n",
      "loss: 0.0008628354407846928\n",
      "output: tensor([[[0.0391],\n",
      "         [0.0141]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.64280504344617 Examples/sec\n",
      "loss: 0.0015696922782808542\n",
      "output: tensor([[[-0.0102],\n",
      "         [ 0.0551]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.75945113933753 Examples/sec\n",
      "loss: 0.00037499782047234476\n",
      "output: tensor([[[-0.0078],\n",
      "         [-0.0263]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "92.38899462296052 Examples/sec\n",
      "loss: 0.024672742933034897\n",
      "output: tensor([[[1.1304],\n",
      "         [0.8873]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.0830],\n",
      "         [0.6703]]])\n",
      "91.73764867232687 Examples/sec\n",
      "loss: 0.003513181582093239\n",
      "output: tensor([[[0.0837],\n",
      "         [0.0038]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "91.97965042214061 Examples/sec\n",
      "loss: 0.004300674423575401\n",
      "output: tensor([[[-0.0880],\n",
      "         [-0.0292]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "84.44241407351049 Examples/sec\n",
      "loss: 0.004393252078443766\n",
      "output: tensor([[[4.9989],\n",
      "         [3.6512]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.0225],\n",
      "         [3.7420]]])\n",
      "93.87317921234771 Examples/sec\n",
      "loss: 0.2737620174884796\n",
      "output: tensor([[[3.5052],\n",
      "         [2.4611]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.1308],\n",
      "         [2.8562]]])\n",
      "95.56666252544463 Examples/sec\n",
      "loss: 1.3864742517471313\n",
      "output: tensor([[[10.7804],\n",
      "         [ 8.6855]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[10.6530],\n",
      "         [ 7.0251]]])\n",
      "96.01877359061244 Examples/sec\n",
      "loss: 0.04686589166522026\n",
      "output: tensor([[[1.8957],\n",
      "         [1.4374]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.0809],\n",
      "         [1.6812]]])\n",
      "97.03801172995486 Examples/sec\n",
      "loss: 1.4798221855016891e-05\n",
      "output: tensor([[[-0.0048],\n",
      "         [ 0.0025]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.31387536214017 Examples/sec\n",
      "loss: 0.029973376542329788\n",
      "output: tensor([[[6.0083],\n",
      "         [3.4766]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.8329],\n",
      "         [3.3057]]])\n",
      "97.27560220893439 Examples/sec\n",
      "loss: 0.014151101000607014\n",
      "output: tensor([[[1.3273],\n",
      "         [0.8434]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.3734],\n",
      "         [0.6816]]])\n",
      "96.47974359543343 Examples/sec\n",
      "loss: 0.005012792535126209\n",
      "output: tensor([[[2.8043],\n",
      "         [2.3192]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.8689],\n",
      "         [2.3957]]])\n",
      "96.07883075906119 Examples/sec\n",
      "loss: 0.000653220689855516\n",
      "output: tensor([[[-0.0071],\n",
      "         [-0.0354]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.02031217255644 Examples/sec\n",
      "loss: 0.0004450096166692674\n",
      "output: tensor([[[0.0278],\n",
      "         [0.0107]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.81563688714492 Examples/sec\n",
      "loss: 0.5253703594207764\n",
      "output: tensor([[[6.1623],\n",
      "         [5.0303]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.9766],\n",
      "         [4.0222]]])\n",
      "96.84911102200992 Examples/sec\n",
      "loss: 0.06542716920375824\n",
      "output: tensor([[[0.3266],\n",
      "         [0.1556]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.70796419097502 Examples/sec\n",
      "loss: 0.005971729289740324\n",
      "output: tensor([[[-0.1084],\n",
      "         [ 0.0141]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.36178875981244 Examples/sec\n",
      "loss: 0.04797617346048355\n",
      "output: tensor([[[2.1508],\n",
      "         [1.5677]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.9701],\n",
      "         [1.3162]]])\n",
      "96.75858732462505 Examples/sec\n",
      "loss: 0.018434200435876846\n",
      "output: tensor([[[0.1891],\n",
      "         [0.0330]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.78761892778675 Examples/sec\n",
      "loss: 0.004994410555809736\n",
      "output: tensor([[[-0.0950],\n",
      "         [-0.0310]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.29569712306976 Examples/sec\n",
      "loss: 0.02453967183828354\n",
      "output: tensor([[[4.0301],\n",
      "         [2.3757]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.2037],\n",
      "         [2.5133]]])\n",
      "96.51512826377972 Examples/sec\n",
      "loss: 0.008919000625610352\n",
      "output: tensor([[[5.8030],\n",
      "         [5.6749]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.8084],\n",
      "         [5.8084]]])\n",
      "96.71254709901044 Examples/sec\n",
      "loss: 0.02445044368505478\n",
      "output: tensor([[[0.2192],\n",
      "         [0.0289]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.79352102887643 Examples/sec\n",
      "loss: 0.004053074400871992\n",
      "output: tensor([[[4.9529],\n",
      "         [4.1318]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.9439],\n",
      "         [4.0423]]])\n",
      "96.81957381959997 Examples/sec\n",
      "loss: 0.001599192270077765\n",
      "output: tensor([[[0.0535],\n",
      "         [0.0182]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.92574433649277 Examples/sec\n",
      "loss: 0.012872300110757351\n",
      "output: tensor([[[4.3273],\n",
      "         [2.7481]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.3815],\n",
      "         [2.8991]]])\n",
      "94.18829936432316 Examples/sec\n",
      "loss: 0.004346917849034071\n",
      "output: tensor([[[-0.0809],\n",
      "         [-0.0464]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.61266049855196 Examples/sec\n",
      "loss: 0.262700617313385\n",
      "output: tensor([[[4.7240],\n",
      "         [4.6757]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.2118],\n",
      "         [5.2118]]])\n",
      "94.2849195985348 Examples/sec\n",
      "loss: 0.0005725256050936878\n",
      "output: tensor([[[0.8398],\n",
      "         [0.6961]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.8391],\n",
      "         [0.6623]]])\n",
      "93.48677629549302 Examples/sec\n",
      "loss: 0.03172518312931061\n",
      "output: tensor([[[11.7186],\n",
      "         [11.7548]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[11.9139],\n",
      "         [11.9139]]])\n",
      "91.80392884093868 Examples/sec\n",
      "loss: 0.00012901844456791878\n",
      "output: tensor([[[-0.0130],\n",
      "         [ 0.0094]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "89.74018421865017 Examples/sec\n",
      "loss: 0.08670051395893097\n",
      "output: tensor([[[7.3597],\n",
      "         [5.7433]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[7.7372],\n",
      "         [5.9190]]])\n",
      "93.89865330551429 Examples/sec\n",
      "loss: 0.0005514340009540319\n",
      "output: tensor([[[0.0309],\n",
      "         [0.0122]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.16027396873314 Examples/sec\n",
      "loss: 0.1256081610918045\n",
      "output: tensor([[[4.7550],\n",
      "         [2.9406]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.4956],\n",
      "         [2.5117]]])\n",
      "96.48300162477375 Examples/sec\n",
      "loss: 0.00036257822648622096\n",
      "output: tensor([[[1.0096],\n",
      "         [1.0344]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.0076],\n",
      "         [1.0076]]])\n",
      "97.12971965449015 Examples/sec\n",
      "loss: 0.00571708008646965\n",
      "output: tensor([[[3.1434],\n",
      "         [2.1517]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.2438],\n",
      "         [2.1149]]])\n",
      "96.3849847615339 Examples/sec\n",
      "loss: 0.013920188881456852\n",
      "output: tensor([[[4.5903],\n",
      "         [3.6780]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.7487],\n",
      "         [3.7302]]])\n",
      "97.21073245370582 Examples/sec\n",
      "loss: 0.003109578974545002\n",
      "output: tensor([[[3.4239],\n",
      "         [2.2871]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.3726],\n",
      "         [2.2272]]])\n",
      "96.72611131047438 Examples/sec\n",
      "loss: 0.0031978085171431303\n",
      "output: tensor([[[0.0714],\n",
      "         [0.0361]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.86853099841426 Examples/sec\n",
      "loss: 0.010120013728737831\n",
      "output: tensor([[[1.6977],\n",
      "         [1.1181]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.5725],\n",
      "         [1.0505]]])\n",
      "96.56881348795932 Examples/sec\n",
      "loss: 0.005326725076884031\n",
      "output: tensor([[[-0.1020],\n",
      "         [-0.0156]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "95.87920753917383 Examples/sec\n",
      "loss: 0.33782830834388733\n",
      "output: tensor([[[5.7262],\n",
      "         [4.8361]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.2227],\n",
      "         [4.1863]]])\n",
      "96.93566961221855 Examples/sec\n",
      "loss: 0.00013571458111982793\n",
      "output: tensor([[[-0.0162],\n",
      "         [-0.0029]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.55119144170239 Examples/sec\n",
      "loss: 0.12500417232513428\n",
      "output: tensor([[[3.4652],\n",
      "         [2.4586]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.2598],\n",
      "         [2.0028]]])\n",
      "96.97928910301917 Examples/sec\n",
      "loss: 0.044421616941690445\n",
      "output: tensor([[[7.2565],\n",
      "         [4.8062]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[6.9959],\n",
      "         [4.6616]]])\n",
      "96.8350434402005 Examples/sec\n",
      "loss: 0.010768922045826912\n",
      "output: tensor([[[3.3787],\n",
      "         [2.4776]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[3.2910],\n",
      "         [2.3599]]])\n",
      "93.88357872936088 Examples/sec\n",
      "loss: 0.0033424037974327803\n",
      "output: tensor([[[1.7446],\n",
      "         [1.3205]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.7630],\n",
      "         [1.2408]]])\n",
      "96.92101325104093 Examples/sec\n",
      "loss: 0.007092733401805162\n",
      "output: tensor([[[4.6899],\n",
      "         [3.0555]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.7625],\n",
      "         [3.1499]]])\n",
      "97.10510267893558 Examples/sec\n",
      "loss: 0.012900547124445438\n",
      "output: tensor([[[2.1205],\n",
      "         [1.2535]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.1996],\n",
      "         [1.1137]]])\n",
      "95.99821827306886 Examples/sec\n",
      "loss: 0.0124661261215806\n",
      "output: tensor([[[1.7170],\n",
      "         [1.3421]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.8522],\n",
      "         [1.4237]]])\n",
      "96.61854419042355 Examples/sec\n",
      "loss: 0.00034296256490051746\n",
      "output: tensor([[[-0.0239],\n",
      "         [-0.0107]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "97.23199943994369 Examples/sec\n",
      "loss: 0.012682176195085049\n",
      "output: tensor([[[2.5419],\n",
      "         [1.7198]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.4266],\n",
      "         [1.6100]]])\n",
      "91.57685266841212 Examples/sec\n",
      "loss: 0.003753834404051304\n",
      "output: tensor([[[1.6427],\n",
      "         [1.0845]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.6964],\n",
      "         [1.1525]]])\n",
      "89.72400000358896 Examples/sec\n",
      "loss: 0.0007447262178175151\n",
      "output: tensor([[[-0.0385],\n",
      "         [-0.0025]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "86.37495540892927 Examples/sec\n",
      "loss: 0.00021016367827542126\n",
      "output: tensor([[[1.3849],\n",
      "         [1.1199]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[1.3879],\n",
      "         [1.1402]]])\n",
      "93.66514523249093 Examples/sec\n",
      "loss: 0.0025463346391916275\n",
      "output: tensor([[[0.0133],\n",
      "         [0.0701]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "93.92422944562162 Examples/sec\n",
      "loss: 0.001972672063857317\n",
      "output: tensor([[[0.0549],\n",
      "         [0.0305]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.53096665144695 Examples/sec\n",
      "loss: 0.0003151238488499075\n",
      "output: tensor([[[-0.0122],\n",
      "         [-0.0219]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.99226971610362 Examples/sec\n",
      "loss: 0.16570356488227844\n",
      "output: tensor([[[7.7395],\n",
      "         [5.6934]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[7.1639],\n",
      "         [5.6837]]])\n",
      "95.8867462462736 Examples/sec\n",
      "loss: 0.07045304775238037\n",
      "output: tensor([[[5.8212],\n",
      "         [4.4162]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[5.9508],\n",
      "         [4.7685]]])\n",
      "93.8433154467974 Examples/sec\n",
      "loss: 0.021084826439619064\n",
      "output: tensor([[[2.2144],\n",
      "         [1.6005]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[2.4196],\n",
      "         [1.6069]]])\n",
      "95.32643106421474 Examples/sec\n",
      "loss: 0.0014277020236477256\n",
      "output: tensor([[[0.5724],\n",
      "         [0.4546]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.5298],\n",
      "         [0.4223]]])\n",
      "92.94500908537465 Examples/sec\n",
      "loss: 0.00018875150999519974\n",
      "output: tensor([[[-0.0145],\n",
      "         [-0.0130]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "96.61004995705684 Examples/sec\n",
      "loss: 0.00039117480628192425\n",
      "output: tensor([[[ 0.0128],\n",
      "         [-0.0249]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n",
      "94.37924411663387 Examples/sec\n",
      "loss: 0.005915034096688032\n",
      "output: tensor([[[4.4683],\n",
      "         [3.3055]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[4.4086],\n",
      "         [3.3964]]])\n",
      "95.07131299187522 Examples/sec\n",
      "loss: 0.0059166643768548965\n",
      "output: tensor([[[0.0824],\n",
      "         [0.0710]]], grad_fn=<CopySlices>)\n",
      "target: tensor([[[0.],\n",
      "         [0.]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5bd28d934ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_cell_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1 \n",
    "INPUT_SEQ_LEN = 2\n",
    "TARGET_SEQ_LEN = 2\n",
    "LEARNING_RATE = 1e-3\n",
    "SAVE_VARIABLE_EVERY = 100\n",
    "DATASET_WORKERS = 4\n",
    "\n",
    "\n",
    "input_seq_len= torch.Tensor([INPUT_SEQ_LEN]).int()\n",
    "target_seq_len= torch.Tensor([TARGET_SEQ_LEN]).int()\n",
    "\n",
    "# Define Data.\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,24),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.2, 0.2\n",
    "                                                                                                                    ])\n",
    "dataloader = DataLoader(cell_load_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=DATASET_WORKERS)\n",
    "\n",
    "# Define Model\n",
    "dynamic_topology_model = DynamicTopologyModel(neighbourhood_hidden_size=32, neighbourhood_cell_count=6,\n",
    "                     neighbourhood_output_size=16, lstm_hidden_size=32, lstm_layers=2, teacher_forcing_probability=0.5, device=device).to(device)\n",
    "\n",
    "parameters = dynamic_topology_model.parameters\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(parameters\n",
    "                       , lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "last_parameters_np = list(np.copy(param.cpu().detach().numpy()) for param in parameters)\n",
    "\n",
    "# Train\n",
    "start = datetime.now()\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    reference_cell_input =  data[0].to(device)\n",
    "    reference_cell_present_input = data[1].to(device)\n",
    "    neighbourhood_cell_rel_input = data[2].to(device)\n",
    "    neighbourhood_cell_load_input = data[3].to(device)\n",
    "    neighbourhood_cell_present_input = data[4].to(device)\n",
    "    reference_cell_target = data[5].to(device)\n",
    "    reference_cell_present_target = data[6].to(device)\n",
    "    neighbourhood_cell_rel_target = data[7].to(device)\n",
    "    neighbourhood_cell_present_target = data[8].to(device)\n",
    "    \n",
    "    \n",
    "    decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n",
    "    \n",
    "    loss = criterion(decoder_output_seq, reference_cell_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx == 0:\n",
    "        parameters = dynamic_topology_model.parameters\n",
    "        parameters_np = list(param.cpu().detach().numpy() for param in parameters)\n",
    "        test_parameters_update(last_parameters_np, parameters_np)\n",
    "        inputs =(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n",
    "        writer.add_graph(dynamic_topology_model, inputs, True)\n",
    "    if batch_idx % SAVE_VARIABLE_EVERY == 0:\n",
    "        #print_example(reference_cell_input, reference_cell_present_input,\n",
    "        #            neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_present_input,\n",
    "        #              reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target,\n",
    "        #              neighbourhood_cell_present_target)    \n",
    "        end = datetime.now()\n",
    "        print(\"{} Examples/sec\".format((SAVE_VARIABLE_EVERY* BATCH_SIZE) / ((end - start).total_seconds()) ))\n",
    "        start = datetime.now()\n",
    "        print(\"loss: {}\".format(loss))\n",
    "        print(\"output: {}\".format(decoder_output_seq))\n",
    "        print(\"target: {}\".format(reference_cell_target))\n",
    "        writer.add_scalar(\"loss\", loss, batch_idx)\n",
    "        save_parameters(writer, dynamic_topology_model, batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS = 640\n",
    "LEFT = 1\n",
    "RIGHT = 3\n",
    "INPUT_SCREEN_COUNT = 2\n",
    "TARGET_SCREEN_COUNT = 2\n",
    "SCREEN_COUNT = INPUT_SCREEN_COUNT + TARGET_SCREEN_COUNT\n",
    "\n",
    "PIXELS_PER_BLOCK = int(PIXELS / IMAGE_SIZE)\n",
    "SCALE_ARR = np.ones((PIXELS_PER_BLOCK, PIXELS_PER_BLOCK, 1))\n",
    "\n",
    "load_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "load_screen[1,12, 0] = 255\n",
    "load_screen[22,22, 0] = 255\n",
    "loads = [(1, 12), (22, 22)]\n",
    "block_img = np.kron(load_screen, SCALE_ARR)\n",
    "\n",
    "screen = pygame.display.set_mode((PIXELS, PIXELS))\n",
    "screens = []\n",
    "\n",
    "screen_draw_idx = 0\n",
    "draw_on = False\n",
    "last_pos = (0, 0)\n",
    "color = (255, 128, 0)\n",
    "radius = 10\n",
    "block_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "model_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell_if_not_exists(new_cell, cells):\n",
    "    cell_already_exists = False\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == new_cell[0] and cell[1] == new_cell[1]:\n",
    "            cell_already_exists = True\n",
    "            break\n",
    "    if not cell_already_exists:\n",
    "        cells.append(new_cell)\n",
    "    return cells\n",
    "\n",
    "def remove_cell_if_exists(remove_cell, cells):\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == remove_cell[0] and cell[1] == remove_cell[1]:\n",
    "            cells.pop(i)\n",
    "            break\n",
    "    return cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 9, 0.65714216), (17, 3, 0.6399348), (18, 9, 0.6347745), (25, 4, 0.62519944), (29, 2, 0.63505596), (28, 29, 0.75098443)]\n",
      "[(6, 9, 0.3775629288350745), (17, 3, 0.34792286298756525), (18, 9, 0.3715000122849831), (25, 4, 0.3196257227995284), (29, 2, 0.2816174963521526), (28, 29, 0.30177097674069625)]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 1 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-218bf712aa65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                                                                 \u001b[0mref_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                                                                 \u001b[0mload_cells_seq_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                                                                                 load_cells_seq_target)\n\u001b[0m\u001b[1;32m     44\u001b[0m            \u001b[0;31m# Infer output from model.  Add batch dimension to each input since dataloader is not used here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m            decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len,\n",
      "\u001b[0;32m~/personal/dynamic_topology/load_topology_dataset.py\u001b[0m in \u001b[0;36mbuild_inputs_and_targets\u001b[0;34m(input_seq_len, target_seq_len, ref_x, ref_y, load_cells_seq_input, load_cells_seq_target)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;31m# neighbourhood normalized by dividing by IMAGE_SIZE.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;31m# Subtract from 1 since cells that are closes have greated influence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mneighbourhood_cell_rel_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0mneighbourhood_cell_rel_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mneighbourhood_cell_present_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
     ]
    }
   ],
   "source": [
    " 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "cells_load_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "BATCH_SIZE=1\n",
    "show_labels = True\n",
    "input_seq_len= torch.Tensor([INPUT_SCREEN_COUNT]).int()\n",
    "target_seq_len= torch.Tensor([TARGET_SCREEN_COUNT]).int()\n",
    "\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,24),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.2, 0.2])\n",
    "\n",
    "data = cell_load_dataset.__getitem__()\n",
    "reference_cell_input =  data[0].to(device)\n",
    "reference_cell_present_input = data[1].to(device)\n",
    "neighbourhood_cell_rel_input = data[2].to(device)\n",
    "neighbourhood_cell_load_input = data[3].to(device)\n",
    "neighbourhood_cell_present_input = data[4].to(device)\n",
    "reference_cell_target = data[5].to(device)\n",
    "reference_cell_present_target = data[6].to(device)\n",
    "neighbourhood_cell_rel_target = data[7].to(device)\n",
    "neighbourhood_cell_present_target = data[8].to(device)                                                                                                                    ])\n",
    "while True:\n",
    "    \n",
    "    ##############################\n",
    "    # Use model to forecast future load\n",
    "    ##############################\n",
    "    load_cells_seq_input = cells_load_seq[:INPUT_SCREEN_COUNT]\n",
    "    load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "    \n",
    " \n",
    "    model_target = [list() for i in range(TARGET_SCREEN_COUNT)]\n",
    "    \n",
    "    if show_labels:\n",
    "        caption = \"Label frame {}\".format(screen_draw_idx)\n",
    "    else:\n",
    "        caption = \"Model frame {}\".format(screen_draw_idx)\n",
    "    pygame.display.set_caption(caption)\n",
    "    for seq_idx  in range(TARGET_SCREEN_COUNT):\n",
    "        for reference_cell in cells_seq[INPUT_SCREEN_COUNT + seq_idx]:\n",
    "            #print(reference_cell)\n",
    "            ref_x, ref_y = reference_cell[0], reference_cell[1]\n",
    "\n",
    "            # Get inputs from state.\n",
    "            (reference_cell_input,\n",
    "             reference_cell_present_input,\n",
    "             neighbourhood_cell_rel_input,\n",
    "             neighbourhood_cell_load_input,\n",
    "             neighbourhood_cell_present_input,\n",
    "             reference_cell_target,\n",
    "             reference_cell_present_target,\n",
    "             neighbourhood_cell_rel_target,\n",
    "             neighbourhood_cell_present_target,) = load_topology_dataset.LoadCellDataset.build_inputs_and_targets(INPUT_SCREEN_COUNT,\n",
    "                                                                                                 TARGET_SCREEN_COUNT,\n",
    "                                                                                                 ref_x, ref_y,\n",
    "                                                                                                 load_cells_seq_input,\n",
    "                                                                                                 load_cells_seq_target)\n",
    "            # Infer output from model.  Add batch dimension to each input since dataloader is not used here.\n",
    "            decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len,\n",
    "                                                                reference_cell_input.unsqueeze(0),\n",
    "                                                                reference_cell_present_input.unsqueeze(0),\n",
    "                                                                neighbourhood_cell_rel_input.unsqueeze(0),\n",
    "                                                                neighbourhood_cell_load_input.unsqueeze(0),\n",
    "                                                                reference_cell_target.unsqueeze(0),\n",
    "                                                                reference_cell_present_target.unsqueeze(0),\n",
    "                                                                neighbourhood_cell_rel_target.unsqueeze(0))\n",
    "\n",
    "            model_target[seq_idx].append((ref_x, ref_y, decoder_output_seq.detach().numpy()[0][seq_idx][0]))    \n",
    "    ################################\n",
    "    # DISPLAY\n",
    "    #################################\n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    cell_loads = cells_load_seq[screen_draw_idx]\n",
    "\n",
    "    if (screen_draw_idx < INPUT_SCREEN_COUNT) or (show_labels and screen_draw_idx >= INPUT_SCREEN_COUNT):\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "    else:\n",
    "        model_loads = model_target[screen_draw_idx - INPUT_SCREEN_COUNT]\n",
    "        for cell in model_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "        \n",
    "        # Update all cell loads\n",
    "        for i, cells in enumerate(cells_seq):\n",
    "            cells_load_seq[i] = load.calculate_cell_load(cells, loads)\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if show_labels:\n",
    "                show_labels = False\n",
    "            else:\n",
    "                show_labels = True\n",
    "                print(model_target[-1])\n",
    "                print(load_cells_seq_target[-1])\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_idx  in range(TARGET_SCREEN_COUNT):\n",
    "    print(seq_idx)\n",
    "    model_target[seq_idx].append((ref_x, ref_y, decoder_output_seq.detach().numpy()[0][seq_idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aeedb4eef06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_output' is not defined"
     ]
    }
   ],
   "source": [
    "decoder_output.detach().numpy()[seq_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
