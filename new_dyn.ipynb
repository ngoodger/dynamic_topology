{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pygame\n",
    "import load\n",
    "from models import DynamicTopologyModel\n",
    "import load_topology_dataset\n",
    "from load_topology_dataset import MAX_CELL_COUNT, MIN_CELL_COUNT, IMAGE_SIZE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "EXPERIMENT=1\n",
    "writer = SummaryWriter('runs/experiment_{}/'.format(EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameters(writer, model, batch_idx):\n",
    "    for k, v in model.state_dict().items():\n",
    "        shape = v.shape\n",
    "        # Don't do this for single weights or biases\n",
    "        if np.any(np.array(shape) > 1):\n",
    "            mean = torch.mean(v)\n",
    "            std_dev = torch.std(v)\n",
    "            maximum = torch.max(v)\n",
    "            minimum = torch.min(v)\n",
    "            writer.add_scalars(\"{}_{} \".format(k, shape), {\"mean\": mean,\n",
    "                                                                    \"std_dev\": std_dev,\n",
    "                                                                    \"max\": maximum,\n",
    "                                                                    \"min\": minimum}, batch_idx)\n",
    "            writer.add_histogram(\"{}_{}\".format(k, shape), v, batch_idx)\n",
    "            \n",
    "        else:\n",
    "            writer.add_scalar(\"{}_{}\".format(k, shape), v.data, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameters_update(last_parameters_np ,parameters_np):\n",
    "    for last_param, param in zip(last_parameters_np, parameters_np):\n",
    "        diff = param - last_param\n",
    "        #print(last_parameters.max())\n",
    "        print(diff.max())\n",
    "        #print(not np.all(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_present_input,\n",
    "                  reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target,\n",
    "                  neighbourhood_cell_present_target):\n",
    "    print(\"reference_cell_input\") \n",
    "    print(reference_cell_input)\n",
    "    print(\"reference_cell_present_input\") \n",
    "    print(reference_cell_present_input)\n",
    "    print(\"neighbourhood_cell_rel_input\") \n",
    "    print(neighbourhood_cell_rel_input)\n",
    "    print(\"neighbourhood_cell_load_input\") \n",
    "    print(neighbourhood_cell_load_input)\n",
    "    print(\"neighbourhood_cell_present_input\") \n",
    "    print(neighbourhood_cell_present_input)\n",
    "    print(\"reference_cell_target\") \n",
    "    print(reference_cell_target)\n",
    "    print(\"reference_cell_present_target\") \n",
    "    print(reference_cell_present_target)\n",
    "    print(\"neighbourhood_cell_rel_target\") \n",
    "    print(neighbourhood_cell_rel_target)\n",
    "    print(\"neighbourhood_cell_present_target\") \n",
    "    print(neighbourhood_cell_present_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00094366074\n",
      "0.0009949803\n",
      "0.0009996295\n",
      "0.0009998679\n",
      "0.00089740753\n",
      "-0.0009992644\n",
      "0.0009987215\n",
      "-0.0009999871\n",
      "0.0009999834\n",
      "0.0\n",
      "0.0009999722\n",
      "0.0009999722\n",
      "0.0009999573\n",
      "0.0\n",
      "0.0009999946\n",
      "0.0009999946\n",
      "0.0\n",
      "0.0\n",
      "0.0009999275\n",
      "0.0009999871\n",
      "0.001000002\n",
      "0.0009999946\n",
      "0.001000002\n",
      "0.0009999424\n",
      "0.000999989\n",
      "0.0009999871\n",
      "0.0009999946\n",
      "0.0009999657\n",
      "0.001000002\n",
      "0.001000002\n",
      "0.001000002\n",
      "0.0009999999\n",
      "graph(%0 : Int(1)\n",
      "      %1 : Int(1)\n",
      "      %2 : Float(32, 2, 1)\n",
      "      %3 : Float(32, 2, 1)\n",
      "      %4 : Float(32, 2, 24, 2)\n",
      "      %5 : Float(32, 2, 24, 1)\n",
      "      %6 : Float(32, 2, 1)\n",
      "      %7 : Float(32, 2, 1)\n",
      "      %8 : Float(32, 2, 24, 2)\n",
      "      %9 : Float(32, 2)\n",
      "      %10 : Float(32)\n",
      "      %11 : Float(32, 1)\n",
      "      %12 : Float(32)\n",
      "      %13 : Float(1, 32)\n",
      "      %14 : Float(1)\n",
      "      %15 : Float(1, 32)\n",
      "      %16 : Float(1)\n",
      "      %17 : Float(128, 3)\n",
      "      %18 : Float(128, 32)\n",
      "      %19 : Float(128)\n",
      "      %20 : Float(128)\n",
      "      %21 : Float(128, 32)\n",
      "      %22 : Float(128, 32)\n",
      "      %23 : Float(128)\n",
      "      %24 : Float(128)\n",
      "      %25 : Float(1, 32)\n",
      "      %26 : Float(1)\n",
      "      %27 : Float(32, 2)\n",
      "      %28 : Float(32)\n",
      "      %29 : Float(16, 32)\n",
      "      %30 : Float(16)\n",
      "      %31 : Float(128, 18)\n",
      "      %32 : Float(128, 32)\n",
      "      %33 : Float(128)\n",
      "      %34 : Float(128)\n",
      "      %35 : Float(128, 32)\n",
      "      %36 : Float(128, 32)\n",
      "      %37 : Float(128)\n",
      "      %38 : Float(128)\n",
      "      %39 : Float(1, 32)\n",
      "      %40 : Float(1)) {\n",
      "  %41 : Long() = onnx::Constant[value={0}](), scope: DynamicTopologyModel\n",
      "  %42 : Tensor = onnx::Shape(%2), scope: DynamicTopologyModel\n",
      "  %43 : Long() = onnx::Gather[axis=0](%42, %41), scope: DynamicTopologyModel\n",
      "  %44 : Long() = onnx::Constant[value={2}](), scope: DynamicTopologyModel\n",
      "  %45 : Long() = onnx::Constant[value={1}](), scope: DynamicTopologyModel\n",
      "  %46 : int[] = prim::ListConstruct(%43, %44, %45), scope: DynamicTopologyModel\n",
      "  %47 : Float(32, 2, 1) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=0](%46), scope: DynamicTopologyModel\n",
      "  return (%47);\n",
      "}\n",
      "\n",
      "4363.168314671699 Examples/sec\n",
      "loss: 3.827908754348755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d854956/personal/dynamic_topology/models.py:196: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  (batch_size, target_seq_len.data.numpy()[0], 1), device=self.device\n",
      "/Users/d854956/personal/dynamic_topology/models.py:200: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for input_seq_idx in range(input_seq_len):\n",
      "/Users/d854956/personal/dynamic_topology/models.py:231: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for target_seq_idx in range(target_seq_len):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017.611223971239 Examples/sec\n",
      "loss: 1.1644065380096436\n",
      "2094.003754810483 Examples/sec\n",
      "loss: 0.32445335388183594\n",
      "1838.6683444515309 Examples/sec\n",
      "loss: 0.1151362806558609\n",
      "2174.8128131815406 Examples/sec\n",
      "loss: 0.04087473079562187\n",
      "2161.5049478199194 Examples/sec\n",
      "loss: 0.039010874927043915\n",
      "2172.103940603818 Examples/sec\n",
      "loss: 0.025958949699997902\n",
      "2065.6449040217462 Examples/sec\n",
      "loss: 0.013768710196018219\n",
      "2176.016624767013 Examples/sec\n",
      "loss: 0.010378601029515266\n",
      "2273.350506601952 Examples/sec\n",
      "loss: 0.016534928232431412\n",
      "2229.211729833471 Examples/sec\n",
      "loss: 0.027125436812639236\n",
      "1962.6952958487154 Examples/sec\n",
      "loss: 0.013313929550349712\n",
      "2186.642212717921 Examples/sec\n",
      "loss: 0.0039010958280414343\n",
      "2287.485453022197 Examples/sec\n",
      "loss: 0.2142162173986435\n",
      "1899.9543417222255 Examples/sec\n",
      "loss: 0.005800675600767136\n",
      "1834.4458483050867 Examples/sec\n",
      "loss: 0.014105859212577343\n",
      "2184.44348571647 Examples/sec\n",
      "loss: 0.012093869969248772\n",
      "2175.2134428190766 Examples/sec\n",
      "loss: 0.031644899398088455\n",
      "2190.294122277276 Examples/sec\n",
      "loss: 0.004738218151032925\n",
      "1737.8034707193692 Examples/sec\n",
      "loss: 0.011883294209837914\n",
      "2216.5899287851216 Examples/sec\n",
      "loss: 0.011652925051748753\n",
      "2219.1847131461036 Examples/sec\n",
      "loss: 0.018053654581308365\n",
      "2145.9644802641683 Examples/sec\n",
      "loss: 0.009048429317772388\n",
      "1997.0269261636738 Examples/sec\n",
      "loss: 0.006279094610363245\n",
      "2235.442380075502 Examples/sec\n",
      "loss: 0.004305791109800339\n",
      "2215.6552661971323 Examples/sec\n",
      "loss: 0.004604941699653864\n",
      "2189.526809045209 Examples/sec\n",
      "loss: 0.008146808482706547\n",
      "1991.2435066793776 Examples/sec\n",
      "loss: 0.007756686769425869\n",
      "2100.5879677008343 Examples/sec\n",
      "loss: 0.00866615492850542\n",
      "2065.2263003987823 Examples/sec\n",
      "loss: 0.013382593169808388\n",
      "2181.7983472877518 Examples/sec\n",
      "loss: 0.006630260962992907\n",
      "1988.8215797085506 Examples/sec\n",
      "loss: 0.007528210524469614\n",
      "2247.1925893206385 Examples/sec\n",
      "loss: 0.007303168065845966\n",
      "2227.647472002996 Examples/sec\n",
      "loss: 0.013751021586358547\n",
      "2234.977112437508 Examples/sec\n",
      "loss: 0.009194803424179554\n",
      "1968.4470244770234 Examples/sec\n",
      "loss: 0.004668132402002811\n",
      "2172.139326446747 Examples/sec\n",
      "loss: 0.009260562248528004\n",
      "2208.4043588381032 Examples/sec\n",
      "loss: 0.00606468366459012\n",
      "2246.4243242825833 Examples/sec\n",
      "loss: 0.0032764242496341467\n",
      "2010.4278378916642 Examples/sec\n",
      "loss: 0.00359110115095973\n",
      "2191.9039288507984 Examples/sec\n",
      "loss: 0.0037487666122615337\n",
      "2220.105413380159 Examples/sec\n",
      "loss: 0.006469677668064833\n",
      "2098.4872530014927 Examples/sec\n",
      "loss: 0.005659386981278658\n",
      "1998.3151705218538 Examples/sec\n",
      "loss: 0.005624146666377783\n",
      "2121.423660901035 Examples/sec\n",
      "loss: 0.0015342546394094825\n",
      "2023.125589946583 Examples/sec\n",
      "loss: 0.007376628462225199\n",
      "2245.495851095556 Examples/sec\n",
      "loss: 0.010147123597562313\n",
      "1954.4980635199656 Examples/sec\n",
      "loss: 0.0055513340048491955\n",
      "2240.0712342652496 Examples/sec\n",
      "loss: 0.004914548713713884\n",
      "2247.9140060496984 Examples/sec\n",
      "loss: 0.009404966607689857\n",
      "2263.3123434689646 Examples/sec\n",
      "loss: 0.0014907735167071223\n",
      "1985.7374408312298 Examples/sec\n",
      "loss: 0.005814497824758291\n",
      "2274.7823317656294 Examples/sec\n",
      "loss: 0.004613370168954134\n",
      "2258.6093601006773 Examples/sec\n",
      "loss: 0.003010241314768791\n",
      "2265.331159559308 Examples/sec\n",
      "loss: 0.003279360244050622\n",
      "1916.863244985905 Examples/sec\n",
      "loss: 0.0018162097549065948\n",
      "2278.24327508862 Examples/sec\n",
      "loss: 0.014413407072424889\n",
      "2268.067103600344 Examples/sec\n",
      "loss: 0.0061719985678792\n",
      "2255.285649546934 Examples/sec\n",
      "loss: 0.0060776397585868835\n",
      "1854.0642827262625 Examples/sec\n",
      "loss: 0.0030238120816648006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e81d2c2008d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n\u001b[0;32m---> 51\u001b[0;31m                 neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_cell_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/dynamic_topology/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input, neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 output = self.neighbourhood_input_embedding(\n\u001b[1;32m    208\u001b[0m                     neighbourhood_cell_rel_input[\n\u001b[0;32m--> 209\u001b[0;31m                         \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbourhood_cell_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                     ],\n\u001b[1;32m    211\u001b[0m                     neighbourhood_cell_load_input[\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32 \n",
    "INPUT_SEQ_LEN = 2\n",
    "TARGET_SEQ_LEN = 2\n",
    "LEARNING_RATE = 1e-3\n",
    "SAVE_VARIABLE_EVERY = 100\n",
    "DATASET_WORKERS = 4\n",
    "\n",
    "\n",
    "input_seq_len= torch.Tensor([INPUT_SEQ_LEN]).int()\n",
    "target_seq_len= torch.Tensor([TARGET_SEQ_LEN]).int()\n",
    "\n",
    "# Define Data.\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,5),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.5, 0.5\n",
    "                                                                                                                    ])\n",
    "dataloader = DataLoader(cell_load_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=DATASET_WORKERS)\n",
    "\n",
    "# Define Model\n",
    "dynamic_topology_model = DynamicTopologyModel(neighbourhood_hidden_size=32, neighbourhood_cell_count=6,\n",
    "                     neighbourhood_output_size=16, lstm_hidden_size=32, lstm_layers=2, teacher_forcing_probability=0.5, device=device).to(device)\n",
    "\n",
    "parameters = dynamic_topology_model.parameters\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(parameters\n",
    "                       , lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "last_parameters_np = list(np.copy(param.cpu().detach().numpy()) for param in parameters)\n",
    "\n",
    "# Train\n",
    "start = datetime.now()\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    reference_cell_input =  data[0].to(device)\n",
    "    reference_cell_present_input = data[1].to(device)\n",
    "    neighbourhood_cell_rel_input = data[2].to(device)\n",
    "    neighbourhood_cell_load_input = data[3].to(device)\n",
    "    neighbourhood_cell_present_input = data[4].to(device)\n",
    "    reference_cell_target = data[5].to(device)\n",
    "    reference_cell_present_target = data[6].to(device)\n",
    "    neighbourhood_cell_rel_target = data[7].to(device)\n",
    "    neighbourhood_cell_present_target = data[8].to(device)\n",
    "    \n",
    "    #print_example(reference_cell_input, reference_cell_present_input,\n",
    "    #            neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_present_input,\n",
    "    #              reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target,\n",
    "    #              neighbourhood_cell_present_target)    \n",
    "    \n",
    "    decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n",
    "    \n",
    "    loss = criterion(decoder_output_seq, reference_cell_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx == 0:\n",
    "        parameters = dynamic_topology_model.parameters\n",
    "        parameters_np = list(param.cpu().detach().numpy() for param in parameters)\n",
    "        test_parameters_update(last_parameters_np, parameters_np)\n",
    "        inputs =(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n",
    "        writer.add_graph(dynamic_topology_model, inputs, True)\n",
    "    if batch_idx % SAVE_VARIABLE_EVERY == 0:\n",
    "        end = datetime.now()\n",
    "        print(\"{} Examples/sec\".format((SAVE_VARIABLE_EVERY* BATCH_SIZE) / ((end - start).total_seconds()) ))\n",
    "        start = datetime.now()\n",
    "        print(\"loss: {}\".format(loss))\n",
    "        #print(\"output: {}\".format(decoder_output_seq))\n",
    "        #print(\"target: {}\".format(reference_cell_target))\n",
    "        writer.add_scalar(\"loss\", loss, batch_idx)\n",
    "        save_parameters(writer, dynamic_topology_model, batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS = 640\n",
    "LEFT = 1\n",
    "RIGHT = 3\n",
    "INPUT_SCREEN_COUNT = 2\n",
    "TARGET_SCREEN_COUNT = 2\n",
    "SCREEN_COUNT = INPUT_SCREEN_COUNT + TARGET_SCREEN_COUNT\n",
    "\n",
    "PIXELS_PER_BLOCK = int(PIXELS / IMAGE_SIZE)\n",
    "SCALE_ARR = np.ones((PIXELS_PER_BLOCK, PIXELS_PER_BLOCK, 1))\n",
    "\n",
    "load_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "load_screen[1,12, 0] = 255\n",
    "load_screen[22,22, 0] = 255\n",
    "loads = [(1, 12), (22, 22)]\n",
    "block_img = np.kron(load_screen, SCALE_ARR)\n",
    "\n",
    "screen = pygame.display.set_mode((PIXELS, PIXELS))\n",
    "screens = []\n",
    "\n",
    "screen_draw_idx = 0\n",
    "draw_on = False\n",
    "last_pos = (0, 0)\n",
    "color = (255, 128, 0)\n",
    "radius = 10\n",
    "block_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "model_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell_if_not_exists(new_cell, cells):\n",
    "    cell_already_exists = False\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == new_cell[0] and cell[1] == new_cell[1]:\n",
    "            cell_already_exists = True\n",
    "            break\n",
    "    if not cell_already_exists:\n",
    "        cells.append(new_cell)\n",
    "    return cells\n",
    "\n",
    "def remove_cell_if_exists(remove_cell, cells):\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == remove_cell[0] and cell[1] == remove_cell[1]:\n",
    "            cells.pop(i)\n",
    "            break\n",
    "    return cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 13, 0.2618928), (16, 13, 0.27077663), (22, 8, 0.26640362)]\n",
      "[(7, 13, 0.6860537046677078), (16, 13, 0.685416716720725), (22, 8, 0.6285295786115672)]\n",
      "[(7, 13, 0.3212703), (16, 13, 0.32657582), (22, 8, 0.32614085)]\n",
      "[(7, 13, 0.6860537046677078), (16, 13, 0.685416716720725), (22, 8, 0.6285295786115672)]\n",
      "[(7, 13, 0.31517512), (16, 13, 0.32657582), (22, 8, 0.32614085)]\n",
      "[(7, 13, 0.6860537046677078), (16, 13, 0.685416716720725), (22, 8, 0.6285295786115672)]\n",
      "[(7, 13, 0.17725854), (16, 13, 0.17838275), (22, 8, 0.16855527), (7, 9, 0.24266964), (25, 4, 0.17919074), (27, 2, 0.18530464)]\n",
      "[(7, 13, 0.3646075985716737), (16, 13, 0.3638785918691302), (22, 8, 0.3335114973407248), (7, 9, 0.3554486627957718), (25, 4, 0.3023787058769728), (27, 2, 0.2801749435457266)]\n",
      "[(7, 13, 0.13601436), (16, 13, 0.13705054), (22, 8, 0.1348989), (7, 9, 0.18295646), (25, 4, 0.14038509), (27, 2, 0.15011573), (10, 22, 0.1638842)]\n",
      "[(7, 13, 0.30819357595053354), (16, 13, 0.3076255430226834), (22, 8, 0.28197354768356153), (7, 9, 0.3004406859200489), (25, 4, 0.25566072651816907), (27, 2, 0.236895973264242), (10, 22, 0.3092099476407616)]\n",
      "[(7, 13, 0.13961653), (16, 13, 0.13341594), (22, 8, 0.1348989), (7, 9, 0.18295646), (25, 4, 0.14363995), (27, 2, 0.15011573), (10, 22, 0.1638842)]\n",
      "[(7, 13, 0.30819357595053354), (16, 13, 0.3076255430226834), (22, 8, 0.28197354768356153), (7, 9, 0.3004406859200489), (25, 4, 0.25566072651816907), (27, 2, 0.236895973264242), (10, 22, 0.3092099476407616)]\n",
      "[(7, 13, 0.26169932), (7, 9, 0.33153066), (27, 2, 0.23521242), (10, 22, 0.26743808)]\n",
      "[(7, 13, 0.5327657981480252), (7, 9, 0.5189361339456111), (27, 2, 0.41226342314843156), (10, 22, 0.536034644757932)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-218bf712aa65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m                                                                \u001b[0mreference_cell_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                                                                \u001b[0mreference_cell_present_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                                                                neighbourhood_cell_rel_target.unsqueeze(0))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m            \u001b[0mmodel_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/dynamic_topology/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input, neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mreference_cell_present_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mtarget_neighbourhood_influence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             )\n\u001b[1;32m    250\u001b[0m             decoder_input = (\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/dynamic_topology/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_input, reference_cell_present_target, target_neighbourhood_influence, decoder_hidden)\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m         output, decoder_hidden = self.lstm(\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mcombined_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         )\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "cells_load_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "BATCH_SIZE=1\n",
    "show_labels = True\n",
    "input_seq_len= torch.Tensor([INPUT_SCREEN_COUNT]).int()\n",
    "target_seq_len= torch.Tensor([TARGET_SCREEN_COUNT]).int()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ##############################\n",
    "    # Use model to forecast future load\n",
    "    ##############################\n",
    "    load_cells_seq_input = cells_load_seq[:INPUT_SCREEN_COUNT]\n",
    "    load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "    \n",
    " \n",
    "    model_target = [list() for i in range(TARGET_SCREEN_COUNT)]\n",
    "    \n",
    "    if show_labels:\n",
    "        caption = \"Label frame {}\".format(screen_draw_idx)\n",
    "    else:\n",
    "        caption = \"Model frame {}\".format(screen_draw_idx)\n",
    "    pygame.display.set_caption(caption)\n",
    "    for seq_idx  in range(TARGET_SCREEN_COUNT):\n",
    "        for reference_cell in cells_seq[INPUT_SCREEN_COUNT + seq_idx]:\n",
    "            #print(reference_cell)\n",
    "            ref_x, ref_y = reference_cell[0], reference_cell[1]\n",
    "\n",
    "            # Get inputs from state.\n",
    "            (reference_cell_input,\n",
    "             reference_cell_present_input,\n",
    "             neighbourhood_cell_rel_input,\n",
    "             neighbourhood_cell_load_input,\n",
    "             neighbourhood_cell_present_input,\n",
    "             reference_cell_target,\n",
    "             reference_cell_present_target,\n",
    "             neighbourhood_cell_rel_target,\n",
    "             neighbourhood_cell_present_target,) = load_topology_dataset.LoadCellDataset.build_inputs_and_targets(INPUT_SCREEN_COUNT,\n",
    "                                                                                                 TARGET_SCREEN_COUNT,\n",
    "                                                                                                 ref_x, ref_y,\n",
    "                                                                                                 load_cells_seq_input,\n",
    "                                                                                                 load_cells_seq_target)\n",
    "            # Infer output from model.  Add batch dimension to each input since dataloader is not used here.\n",
    "            decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len,\n",
    "                                                                reference_cell_input.unsqueeze(0),\n",
    "                                                                reference_cell_present_input.unsqueeze(0),\n",
    "                                                                neighbourhood_cell_rel_input.unsqueeze(0),\n",
    "                                                                neighbourhood_cell_load_input.unsqueeze(0),\n",
    "                                                                reference_cell_target.unsqueeze(0),\n",
    "                                                                reference_cell_present_target.unsqueeze(0),\n",
    "                                                                neighbourhood_cell_rel_target.unsqueeze(0))\n",
    "\n",
    "            model_target[seq_idx].append((ref_x, ref_y, decoder_output_seq.detach().numpy()[0][seq_idx][0]))    \n",
    "    ################################\n",
    "    # DISPLAY\n",
    "    #################################\n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    cell_loads = cells_load_seq[screen_draw_idx]\n",
    "\n",
    "    if (screen_draw_idx < INPUT_SCREEN_COUNT) or (show_labels and screen_draw_idx >= INPUT_SCREEN_COUNT):\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "    else:\n",
    "        model_loads = model_target[screen_draw_idx - INPUT_SCREEN_COUNT]\n",
    "        for cell in model_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "        \n",
    "        # Update all cell loads\n",
    "        for i, cells in enumerate(cells_seq):\n",
    "            cells_load_seq[i] = load.calculate_cell_load(cells, loads)\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if show_labels:\n",
    "                show_labels = False\n",
    "            else:\n",
    "                show_labels = True\n",
    "                print(model_target[-1])\n",
    "                print(load_cells_seq_target[-1])\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for seq_idx  in range(TARGET_SCREEN_COUNT):\n",
    "    print(seq_idx)\n",
    "    model_target[seq_idx].append((ref_x, ref_y, decoder_output_seq.detach().numpy()[0][seq_idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aeedb4eef06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_output' is not defined"
     ]
    }
   ],
   "source": [
    "decoder_output.detach().numpy()[seq_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
