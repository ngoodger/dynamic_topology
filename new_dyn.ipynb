{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import load\n",
    "from models import DynamicTopologyModel\n",
    "import load_topology_dataset\n",
    "from load_topology_dataset import MAX_CELL_COUNT, MIN_CELL_COUNT, IMAGE_SIZE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "EXPERIMENT=1\n",
    "writer = SummaryWriter('runs/experiment_{}/'.format(EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameters(writer, model, batch_idx):\n",
    "    for k, v in model.state_dict().items():\n",
    "        shape = v.shape\n",
    "        # Don't do this for single weights or biases\n",
    "        if np.any(np.array(shape) > 1):\n",
    "            mean = torch.mean(v)\n",
    "            std_dev = torch.std(v)\n",
    "            maximum = torch.max(v)\n",
    "            minimum = torch.min(v)\n",
    "            writer.add_scalars(\"{}_{} \".format(k, shape), {\"mean\": mean,\n",
    "                                                                    \"std_dev\": std_dev,\n",
    "                                                                    \"max\": maximum,\n",
    "                                                                    \"min\": minimum}, batch_idx)\n",
    "            writer.add_histogram(\"{}_{}\".format(k, shape), v, batch_idx)\n",
    "            \n",
    "        else:\n",
    "            writer.add_scalar(\"{}_{}\".format(k, shape), v.data, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameters_update(last_parameters_np ,parameters_np):\n",
    "    for last_param, param in zip(last_parameters_np, parameters_np):\n",
    "        diff = param - last_param\n",
    "        #print(last_parameters.max())\n",
    "        print(diff.max())\n",
    "        #print(not np.all(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_present_input,\n",
    "                  reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target,\n",
    "                  neighbourhood_cell_present_target):\n",
    "    print(\"reference_cell_input\") \n",
    "    print(reference_cell_input)\n",
    "    print(\"reference_cell_present_input\") \n",
    "    print(reference_cell_present_input)\n",
    "    print(\"neighbourhood_cell_rel_input\") \n",
    "    print(neighbourhood_cell_rel_input)\n",
    "    print(\"neighbourhood_cell_load_input\") \n",
    "    print(neighbourhood_cell_load_input)\n",
    "    print(\"neighbourhood_cell_present_input\") \n",
    "    print(neighbourhood_cell_present_input)\n",
    "    print(\"reference_cell_target\") \n",
    "    print(reference_cell_target)\n",
    "    print(\"reference_cell_present_target\") \n",
    "    print(reference_cell_present_target)\n",
    "    print(\"neighbourhood_cell_rel_target\") \n",
    "    print(neighbourhood_cell_rel_target)\n",
    "    print(\"neighbourhood_cell_present_target\") \n",
    "    print(neighbourhood_cell_present_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009558499\n",
      "0.0009992719\n",
      "0.0009872317\n",
      "0.0009997487\n",
      "0.0009997934\n",
      "0.0009998679\n",
      "0.0009999573\n",
      "0.0009999555\n",
      "0.0009999871\n",
      "0.0\n",
      "0.0009999461\n",
      "0.0009999424\n",
      "0.0009999424\n",
      "0.0\n",
      "0.0009999871\n",
      "0.000999988\n",
      "0.0\n",
      "0.0\n",
      "0.0009994209\n",
      "0.0009999871\n",
      "0.001000002\n",
      "0.001000002\n",
      "0.001000002\n",
      "0.0009999871\n",
      "0.0009999946\n",
      "0.0009999946\n",
      "0.001000002\n",
      "0.0009999946\n",
      "0.001000002\n",
      "0.001000002\n",
      "0.001000002\n",
      "0.001000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d854956/personal/dynamic_topology/models.py:196: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  (batch_size, target_seq_len.data.numpy()[0], 1), device=self.device\n",
      "/Users/d854956/personal/dynamic_topology/models.py:200: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for input_seq_idx in range(input_seq_len):\n",
      "/Users/d854956/personal/dynamic_topology/models.py:231: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for target_seq_idx in range(target_seq_len):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Int(1)\n",
      "      %1 : Int(1)\n",
      "      %2 : Float(8, 8, 1)\n",
      "      %3 : Float(8, 8, 1)\n",
      "      %4 : Float(8, 8, 6, 2)\n",
      "      %5 : Float(8, 8, 6, 1)\n",
      "      %6 : Float(8, 8, 1)\n",
      "      %7 : Float(8, 8, 1)\n",
      "      %8 : Float(8, 8, 6, 2)\n",
      "      %9 : Float(32, 2)\n",
      "      %10 : Float(32)\n",
      "      %11 : Float(32, 1)\n",
      "      %12 : Float(32)\n",
      "      %13 : Float(1, 32)\n",
      "      %14 : Float(1)\n",
      "      %15 : Float(1, 32)\n",
      "      %16 : Float(1)\n",
      "      %17 : Float(128, 3)\n",
      "      %18 : Float(128, 32)\n",
      "      %19 : Float(128)\n",
      "      %20 : Float(128)\n",
      "      %21 : Float(128, 32)\n",
      "      %22 : Float(128, 32)\n",
      "      %23 : Float(128)\n",
      "      %24 : Float(128)\n",
      "      %25 : Float(1, 32)\n",
      "      %26 : Float(1)\n",
      "      %27 : Float(32, 2)\n",
      "      %28 : Float(32)\n",
      "      %29 : Float(16, 32)\n",
      "      %30 : Float(16)\n",
      "      %31 : Float(128, 18)\n",
      "      %32 : Float(128, 32)\n",
      "      %33 : Float(128)\n",
      "      %34 : Float(128)\n",
      "      %35 : Float(128, 32)\n",
      "      %36 : Float(128, 32)\n",
      "      %37 : Float(128)\n",
      "      %38 : Float(128)\n",
      "      %39 : Float(1, 32)\n",
      "      %40 : Float(1)) {\n",
      "  %41 : Long() = onnx::Constant[value={0}](), scope: DynamicTopologyModel\n",
      "  %42 : Tensor = onnx::Shape(%2), scope: DynamicTopologyModel\n",
      "  %43 : Long() = onnx::Gather[axis=0](%42, %41), scope: DynamicTopologyModel\n",
      "  %44 : Long() = onnx::Constant[value={8}](), scope: DynamicTopologyModel\n",
      "  %45 : Long() = onnx::Constant[value={1}](), scope: DynamicTopologyModel\n",
      "  %46 : int[] = prim::ListConstruct(%43, %44, %45), scope: DynamicTopologyModel\n",
      "  %47 : Float(8, 8, 1) = onnx::ConstantFill[dtype=1, input_as_shape=1, value=0](%46), scope: DynamicTopologyModel\n",
      "  return (%47);\n",
      "}\n",
      "\n",
      "1370.8582943781103 Examples/sec\n",
      "loss: 7.335844039916992\n",
      "247.24216814074506 Examples/sec\n",
      "loss: 2.7206873893737793\n",
      "235.80345310576726 Examples/sec\n",
      "loss: 3.4322078227996826\n",
      "265.1098532384991 Examples/sec\n",
      "loss: 0.19603367149829865\n",
      "269.269062398393 Examples/sec\n",
      "loss: 1.1904716491699219\n",
      "267.62727014831904 Examples/sec\n",
      "loss: 0.40375515818595886\n",
      "266.9140069798013 Examples/sec\n",
      "loss: 0.12864002585411072\n",
      "268.00831629805475 Examples/sec\n",
      "loss: 0.2296266406774521\n",
      "260.84172319867594 Examples/sec\n",
      "loss: 0.056218113750219345\n",
      "234.78263676748918 Examples/sec\n",
      "loss: 0.03053571656346321\n",
      "277.99892205917973 Examples/sec\n",
      "loss: 0.030903303995728493\n",
      "267.8113817828672 Examples/sec\n",
      "loss: 0.011991353705525398\n",
      "264.8288427740954 Examples/sec\n",
      "loss: 0.002378742443397641\n",
      "257.04355570921047 Examples/sec\n",
      "loss: 0.0028182631358504295\n",
      "278.89315672889006 Examples/sec\n",
      "loss: 0.01642618328332901\n",
      "268.3474159821012 Examples/sec\n",
      "loss: 0.013745381496846676\n",
      "263.91604566671293 Examples/sec\n",
      "loss: 0.00916957575827837\n",
      "281.10160909588586 Examples/sec\n",
      "loss: 0.0146676916629076\n",
      "272.2455219014716 Examples/sec\n",
      "loss: 0.002401958918198943\n",
      "260.7572128704545 Examples/sec\n",
      "loss: 0.01601353846490383\n",
      "264.76635031500575 Examples/sec\n",
      "loss: 0.011169396340847015\n",
      "276.8336596510096 Examples/sec\n",
      "loss: 0.028791388496756554\n",
      "251.23095316081512 Examples/sec\n",
      "loss: 0.007787635084241629\n",
      "268.698474968218 Examples/sec\n",
      "loss: 0.03662429749965668\n",
      "266.3635449525107 Examples/sec\n",
      "loss: 0.0013417236041277647\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5e945a27f6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_cell_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# BATCH SIZE STILL NOT WORKING!!!\n",
    "\n",
    "BATCH_SIZE = 8 \n",
    "INPUT_SEQ_LEN = 8 \n",
    "TARGET_SEQ_LEN = 8\n",
    "LEARNING_RATE = 1e-3\n",
    "SAVE_VARIABLE_EVERY = 100\n",
    "DATASET_WORKERS = 2\n",
    "\n",
    "\n",
    "input_seq_len= torch.Tensor([INPUT_SEQ_LEN]).int()\n",
    "target_seq_len= torch.Tensor([TARGET_SEQ_LEN]).int()\n",
    "\n",
    "# Define Data.\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,5),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.5, 0.5\n",
    "                                                                                                                    ])\n",
    "dataloader = DataLoader(cell_load_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=DATASET_WORKERS)\n",
    "\n",
    "# Define Model\n",
    "dynamic_topology_model = DynamicTopologyModel(neighbourhood_hidden_size=32, neighbourhood_cell_count=6,\n",
    "                     neighbourhood_output_size=16, lstm_hidden_size=32, lstm_layers=2, teacher_forcing_probability=0.5, device=device).to(device)\n",
    "\n",
    "parameters = dynamic_topology_model.parameters\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(parameters\n",
    "                       , lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "last_parameters_np = list(np.copy(param.cpu().detach().numpy()) for param in parameters)\n",
    "\n",
    "# Train\n",
    "start = datetime.now()\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    reference_cell_input =  data[0].to(device)\n",
    "    reference_cell_present_input = data[1].to(device)\n",
    "    neighbourhood_cell_rel_input = data[2].to(device)\n",
    "    neighbourhood_cell_load_input = data[3].to(device)\n",
    "    neighbourhood_cell_present_input = data[4].to(device)\n",
    "    reference_cell_target = data[5].to(device)\n",
    "    reference_cell_present_target = data[6].to(device)\n",
    "    neighbourhood_cell_rel_target = data[7].to(device)\n",
    "    neighbourhood_cell_present_target = data[8].to(device)\n",
    "    \n",
    "    #print_example(reference_cell_input, reference_cell_present_input,\n",
    "    #            neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_present_input,\n",
    "    #              reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target,\n",
    "    #              neighbourhood_cell_present_target)    \n",
    "    \n",
    "    decoder_output_seq = dynamic_topology_model.forward(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n",
    "    \n",
    "    loss = criterion(decoder_output_seq, reference_cell_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx == 0:\n",
    "        parameters = dynamic_topology_model.parameters\n",
    "        parameters_np = list(param.cpu().detach().numpy() for param in parameters)\n",
    "        test_parameters_update(last_parameters_np, parameters_np)\n",
    "        inputs =(input_seq_len, target_seq_len, reference_cell_input, reference_cell_present_input,\n",
    "                neighbourhood_cell_rel_input, neighbourhood_cell_load_input, reference_cell_target, reference_cell_present_target, neighbourhood_cell_rel_target)\n",
    "        writer.add_graph(dynamic_topology_model, inputs, True)\n",
    "    if batch_idx % SAVE_VARIABLE_EVERY == 0:\n",
    "        end = datetime.now()\n",
    "        print(\"{} Examples/sec\".format((SAVE_VARIABLE_EVERY* BATCH_SIZE) / ((end - start).total_seconds()) ))\n",
    "        start = datetime.now()\n",
    "        print(\"loss: {}\".format(loss))\n",
    "        #print(\"output: {}\".format(decoder_output_seq))\n",
    "        #print(\"target: {}\".format(reference_cell_target))\n",
    "        writer.add_scalar(\"loss\", loss, batch_idx)\n",
    "        save_parameters(writer, dynamic_topology_model, batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS = 640\n",
    "LEFT = 1\n",
    "RIGHT = 3\n",
    "INPUT_SCREEN_COUNT = 1\n",
    "TARGET_SCREEN_COUNT = 1\n",
    "SCREEN_COUNT = INPUT_SCREEN_COUNT + TARGET_SCREEN_COUNT\n",
    "\n",
    "PIXELS_PER_BLOCK = int(PIXELS / IMAGE_SIZE)\n",
    "SCALE_ARR = np.ones((PIXELS_PER_BLOCK, PIXELS_PER_BLOCK, 1))\n",
    "\n",
    "load_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "load_screen[1,12, 0] = 255\n",
    "load_screen[22,22, 0] = 255\n",
    "loads = [(1, 12), (22, 22)]\n",
    "block_img = np.kron(load_screen, SCALE_ARR)\n",
    "\n",
    "screen = pygame.display.set_mode((PIXELS, PIXELS))\n",
    "screens = []\n",
    "\n",
    "screen_draw_idx = 0\n",
    "draw_on = False\n",
    "last_pos = (0, 0)\n",
    "color = (255, 128, 0)\n",
    "radius = 10\n",
    "block_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "model_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "frame = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   model_target = [list() for i in range(TARGET_SCREEN_COUNT)]\n",
    "    for reference_cell in cells_seq[-1]:\n",
    "        #print(reference_cell)\n",
    "        ref_x, ref_y = reference_cell[0], reference_cell[1]\n",
    "        reference_cell_input = np.zeros((INPUT_SCREEN_COUNT))\n",
    "        reference_cell_present_input = np.zeros((INPUT_SCREEN_COUNT))\n",
    "        neighbourhood_cell_rel_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT, 2))\n",
    "        neighbourhood_cell_load_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT))\n",
    "        neighbourhood_cell_present_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT))\n",
    "        for seq_idx in range(INPUT_SCREEN_COUNT):\n",
    "            reference_cell_active = False\n",
    "            cell_idx = 0\n",
    "            for cell in load_cells_seq_input[seq_idx]:\n",
    "                current_x = cell[0]\n",
    "                current_y = cell[1]\n",
    "                current_load = cell[2]\n",
    "                # If not reference cell add to neighbourhood\n",
    "                if not (current_x == ref_x and current_y == ref_y):\n",
    "                    # neighbourhood normalized by dividing by IMAGE_SIZE.\n",
    "                    # Subtract from 1 since cells that are closes have greated influence.\n",
    "                    #print(\"seq_idx {}\".format(seq_idx))\n",
    "                    #print(\"cell_idx {}\".format(cell_idx))\n",
    "                    neighbourhood_cell_rel_input[seq_idx, cell_idx, 0] = 1. - abs(ref_x - current_x) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_rel_input[seq_idx, cell_idx, 1] = 1. - abs(ref_y - current_y) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_load_input[seq_idx, cell_idx] = current_load\n",
    "                    cell_idx += 1\n",
    "                else:\n",
    "                    # print(\"ref cell\")\n",
    "                    reference_cell_input[seq_idx] = current_load\n",
    "                    reference_cell_active = True\n",
    "            if reference_cell_active:\n",
    "                reference_cell_present_input[seq_idx] = 1.0\n",
    "\n",
    "        load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "        reference_cell_present_target = np.zeros((TARGET_SCREEN_COUNT))\n",
    "        neighbourhood_cell_rel_target = np.zeros((TARGET_SCREEN_COUNT, MAX_CELL_COUNT, 2))\n",
    "\n",
    "\n",
    "        for seq_idx in range(TARGET_SCREEN_COUNT):\n",
    "            reference_cell_active = False\n",
    "            cell_idx = 0\n",
    "            for cell in load_cells_seq_target[seq_idx]:\n",
    "                current_x = cell[0]\n",
    "                current_y = cell[1]\n",
    "                current_load = cell[2]\n",
    "                #print(current_load)\n",
    "                # If not reference cell add to neighbourhood\n",
    "                if not (current_x == ref_x and current_y == ref_y):\n",
    "                    # neighbourhood normalized by dividing by IMAGE_SIZE.\n",
    "                    # Subtract from 1 since cells that are closes have greated influence.\n",
    "                    neighbourhood_cell_rel_target[seq_idx, cell_idx, 0] = 1. - abs(ref_x - current_x) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_rel_target[seq_idx, cell_idx, 1] = 1. - abs(ref_y - current_y) / IMAGE_SIZE\n",
    "                    cell_idx += 1\n",
    "                else:\n",
    "                    reference_cell_active = True\n",
    "            if reference_cell_active:\n",
    "                reference_cell_present_target[seq_idx] = 1.0\n",
    "\n",
    "        reference_cell_input = torch.tensor(reference_cell_input, dtype=torch.float32).unsqueeze(0)\n",
    "        reference_cell_present_input = torch.tensor(reference_cell_present_input, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_rel_input = torch.tensor(neighbourhood_cell_rel_input, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_load_input = torch.tensor(neighbourhood_cell_load_input, dtype=torch.float32).unsqueeze(0)\n",
    "        reference_cell_present_target = torch.tensor(reference_cell_present_target, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_rel_target = torch.tensor(neighbourhood_cell_rel_target, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        model_target[seq_idx].append((ref_x, ref_y, decoder_output.detach().numpy()[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "cells_load_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "BATCH_SIZE=1\n",
    "show_labels = True\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ##############################\n",
    "    # Use model to forecast future load\n",
    "    ##############################\n",
    "    load_cells_seq_input = cells_load_seq[:INPUT_SCREEN_COUNT]\n",
    "    load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "    \n",
    " \n",
    "            \n",
    "    ################################\n",
    "    # DISPLAY\n",
    "    #################################\n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    cell_loads = cells_load_seq[screen_draw_idx]\n",
    "\n",
    "    if (screen_draw_idx < INPUT_SCREEN_COUNT) or (show_labels and screen_draw_idx >= INPUT_SCREEN_COUNT):\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "    else:\n",
    "        model_loads = model_target[screen_draw_idx - INPUT_SCREEN_COUNT]\n",
    "        for cell in model_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "        \n",
    "        # Update all cell loads\n",
    "        for i, cells in enumerate(cells_seq):\n",
    "            cells_load_seq[i] = load.calculate_cell_load(cells, loads)\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if show_labels:\n",
    "                show_labels = False\n",
    "            else:\n",
    "                show_labels = True\n",
    "                print(model_target[-1])\n",
    "                print(load_cells_seq_target[-1])\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
