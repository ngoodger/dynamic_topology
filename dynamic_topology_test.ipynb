{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import random\n",
    "import pygame\n",
    "import math\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import load\n",
    "from models import EncoderRNN, DecoderRNN, NeighbourhoodFullyConnected, NeighbourhoodFullyConnectedDecoder\n",
    "import load_topology_dataset\n",
    "from load_topology_dataset import MAX_CELL_COUNT, MIN_CELL_COUNT, IMAGE_SIZE\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplifying Assumptions\n",
    "1. No multiple carriers.\n",
    "2. Locations of loads and cells discretized to grid of resolution IMAGE_SIZE\n",
    "3. Cells are not limited by capacity\n",
    "4. Distribution of load follows inverse square of distance.\n",
    "5. Cells are omnidirectional.\n",
    "6. Load is constant.\n",
    "7. Only a maximum of 1 cell changes (addition or removal) at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 12, 0.6709275647328745), (31, 0, 0.3290724352671256)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loads = ((1,12), (22, 22))\n",
    "test_loads = [(1,12)]\n",
    "test_cells = [(2, 12), (31, 0)]\n",
    "load.calculate_cell_load(cells=test_cells, loads=test_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "PIXELS = 640\n",
    "LEFT = 1\n",
    "RIGHT = 3\n",
    "INPUT_SCREEN_COUNT = 2\n",
    "TARGET_SCREEN_COUNT = 2\n",
    "SCREEN_COUNT = INPUT_SCREEN_COUNT + TARGET_SCREEN_COUNT\n",
    "\n",
    "PIXELS_PER_BLOCK = int(PIXELS / IMAGE_SIZE)\n",
    "SCALE_ARR = np.ones((PIXELS_PER_BLOCK, PIXELS_PER_BLOCK, 1))\n",
    "print(PIXELS_PER_BLOCK)\n",
    "\n",
    "load_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "load_screen[1,12, 0] = 255\n",
    "load_screen[22,22, 0] = 255\n",
    "loads = [(1, 12), (22, 22)]\n",
    "block_img = np.kron(load_screen, SCALE_ARR)\n",
    "\n",
    "screen = pygame.display.set_mode((PIXELS, PIXELS))\n",
    "screens = []\n",
    "\n",
    "#for i in range(SCREEN_COUNT):\n",
    "##    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "#    screens.append(screen_draw)\n",
    "\n",
    "\n",
    "screen_draw_idx = 0\n",
    "\n",
    "\n",
    "draw_on = False\n",
    "last_pos = (0, 0)\n",
    "color = (255, 128, 0)\n",
    "radius = 10\n",
    "device = \"cpu\"\n",
    "\n",
    "block_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "model_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "frame = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"abc\", \"def\", \"ghi\", \"jkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ghi', 'jkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell_if_not_exists(new_cell, cells):\n",
    "    cell_already_exists = False\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == new_cell[0] and cell[1] == new_cell[1]:\n",
    "            cell_already_exists = True\n",
    "            break\n",
    "    if not cell_already_exists:\n",
    "        cells.append(new_cell)\n",
    "    return cells\n",
    "\n",
    "def remove_cell_if_exists(remove_cell, cells):\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == remove_cell[0] and cell[1] == remove_cell[1]:\n",
    "            cells.pop(i)\n",
    "            break\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 13, 2.1651034), (31, 30, 0.51882005), (30, 29, 0.51775223), (29, 28, 0.5157211), (28, 27, 0.51380646)]\n",
      "[(12, 13, 0.52716680413611), (31, 30, 0.33990757386327436), (30, 29, 0.35951307994079995), (29, 28, 0.37801105200473534), (28, 27, 0.3954014900550805)]\n",
      "[(12, 13, 2.1651034), (31, 30, 0.51882005), (30, 29, 0.51775223), (29, 28, 0.5157211), (28, 27, 0.51380646)]\n",
      "[(12, 13, 0.52716680413611), (31, 30, 0.33990757386327436), (30, 29, 0.35951307994079995), (29, 28, 0.37801105200473534), (28, 27, 0.3954014900550805)]\n",
      "[(12, 13, 2.1651034), (31, 30, 0.51882005), (30, 29, 0.51775223), (29, 28, 0.5157211), (28, 27, 0.51380646), (14, 14, 0.4777406)]\n",
      "[(12, 13, 0.41322526192672404), (31, 30, 0.2721889121335957), (30, 29, 0.2872491090183028), (29, 28, 0.3014405157593933), (28, 27, 0.31476313235686726), (14, 14, 0.4111330688051169)]\n",
      "[(12, 13, 2.1651034), (31, 30, 0.51882005), (30, 29, 0.51775223), (29, 28, 0.5157211), (28, 27, 0.51380646), (14, 14, 0.4777406)]\n",
      "[(12, 13, 0.41322526192672404), (31, 30, 0.2721889121335957), (30, 29, 0.2872491090183028), (29, 28, 0.3014405157593933), (28, 27, 0.31476313235686726), (14, 14, 0.4111330688051169)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2a7336fd7a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m                                                          \u001b[0mreference_cell_present_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_idx\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                                                          \u001b[0mneighbourhood_influence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                                                          decoder_hidden)\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mmodel_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/dynamic_topology/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, input_present, neighbourhood, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcombined_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_present\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbourhood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "screen_draw_idx = 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "cells_load_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "BATCH_SIZE=1\n",
    "show_labels = True\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ##############################\n",
    "    # Use model to forecast future load\n",
    "    ##############################\n",
    "    load_cells_seq_input = cells_load_seq[:INPUT_SCREEN_COUNT]\n",
    "    load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "    \n",
    "    model_target = [list() for i in range(TARGET_SCREEN_COUNT)]\n",
    "    for reference_cell in cells_seq[-1]:\n",
    "        #print(reference_cell)\n",
    "        ref_x, ref_y = reference_cell[0], reference_cell[1]\n",
    "        reference_cell_input = np.zeros((INPUT_SCREEN_COUNT))\n",
    "        reference_cell_present_input = np.zeros((INPUT_SCREEN_COUNT))\n",
    "        neighbourhood_cell_rel_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT, 2))\n",
    "        neighbourhood_cell_load_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT))\n",
    "        neighbourhood_cell_present_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT))\n",
    "        for seq_idx in range(INPUT_SCREEN_COUNT):\n",
    "            reference_cell_active = False\n",
    "            cell_idx = 0\n",
    "            for cell in load_cells_seq_input[seq_idx]:\n",
    "                current_x = cell[0]\n",
    "                current_y = cell[1]\n",
    "                current_load = cell[2]\n",
    "                # If not reference cell add to neighbourhood\n",
    "                if not (current_x == ref_x and current_y == ref_y):\n",
    "                    # neighbourhood normalized by dividing by IMAGE_SIZE.\n",
    "                    # Subtract from 1 since cells that are closes have greated influence.\n",
    "                    #print(\"seq_idx {}\".format(seq_idx))\n",
    "                    #print(\"cell_idx {}\".format(cell_idx))\n",
    "                    neighbourhood_cell_rel_input[seq_idx, cell_idx, 0] = 1. - (ref_x - current_x) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_rel_input[seq_idx, cell_idx, 1] = 1. - (ref_y - current_y) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_load_input[seq_idx, cell_idx] = current_load\n",
    "                    cell_idx += 1\n",
    "                else:\n",
    "                    # print(\"ref cell\")\n",
    "                    reference_cell_input[seq_idx] = current_load\n",
    "                    reference_cell_active = True\n",
    "            if reference_cell_active:\n",
    "                reference_cell_present_input[seq_idx] = 1.0\n",
    "\n",
    "        load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "        reference_cell_present_target = np.zeros((TARGET_SCREEN_COUNT))\n",
    "        neighbourhood_cell_rel_target = np.zeros((TARGET_SCREEN_COUNT, MAX_CELL_COUNT, 2))\n",
    "\n",
    "\n",
    "        for seq_idx in range(TARGET_SCREEN_COUNT):\n",
    "            reference_cell_active = False\n",
    "            cell_idx = 0\n",
    "            for cell in load_cells_seq_target[seq_idx]:\n",
    "                current_x = cell[0]\n",
    "                current_y = cell[1]\n",
    "                current_load = cell[2]\n",
    "                #print(current_load)\n",
    "                # If not reference cell add to neighbourhood\n",
    "                if not (current_x == ref_x and current_y == ref_y):\n",
    "                    # neighbourhood normalized by dividing by IMAGE_SIZE.\n",
    "                    # Subtract from 1 since cells that are closes have greated influence.\n",
    "                    neighbourhood_cell_rel_target[seq_idx, cell_idx, 0] = 1. - abs(ref_x - current_x) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_rel_target[seq_idx, cell_idx, 1] = 1. - abs(ref_y - current_y) / IMAGE_SIZE\n",
    "                    cell_idx += 1\n",
    "                else:\n",
    "                    reference_cell_active = True\n",
    "            if reference_cell_active:\n",
    "                reference_cell_present_target[seq_idx] = 1.0\n",
    "\n",
    "        reference_cell_input = torch.tensor(reference_cell_input, dtype=torch.float32).unsqueeze(0)\n",
    "        reference_cell_present_input = torch.tensor(reference_cell_present_input, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_rel_input = torch.tensor(neighbourhood_cell_rel_input, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_load_input = torch.tensor(neighbourhood_cell_load_input, dtype=torch.float32).unsqueeze(0)\n",
    "        reference_cell_present_target = torch.tensor(reference_cell_present_target, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_rel_target = torch.tensor(neighbourhood_cell_rel_target, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        for seq_idx in range(INPUT_SCREEN_COUNT):\n",
    "            neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "            for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "                output = neighbourhood_fully_connected(neighbourhood_cell_rel_input[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2),\n",
    "                                              neighbourhood_cell_load_input[:,seq_idx, neighbourhood_cell_idx].view(BATCH_SIZE, 1))\n",
    "                neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "            # Concatonate neighbourhood with reference cell time series.\n",
    "            cat_ref_input = (torch.cat((reference_cell_input[:, seq_idx].view(BATCH_SIZE, 1),\n",
    "                                                reference_cell_present_input[:, seq_idx].view(BATCH_SIZE, 1)), dim=1))\n",
    "            encoder_input = torch.cat((cat_ref_input , neighbourhood_influence), dim=1).view(BATCH_SIZE, 1, 1 + 1+ 16)\n",
    "            if seq_idx==0:\n",
    "                encoder_hidden = torch.zeros(1, BATCH_SIZE, HIDDEN_SIZE, device=device)\n",
    "            encoder_output, encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "        #print(\"encoder_hidden {}\".format(encoder_hidden))\n",
    "\n",
    "        for seq_idx in range(TARGET_SCREEN_COUNT):\n",
    "            neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "\n",
    "            #print(\"reference_cell_input {}\".format(reference_cell_input))\n",
    "            \n",
    "            for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "                output = neighbourhood_fully_connected_decoder(neighbourhood_cell_rel_target[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2))\n",
    "                neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "\n",
    "            #print(\"output {}\".format(output))\n",
    "            #print(\"neighbourhood_influence {}\".format(neighbourhood_influence))\n",
    "            if seq_idx==0:\n",
    "                decoder_output, decoder_hidden = decoder(reference_cell_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                         reference_cell_present_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                         neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                         encoder_hidden)\n",
    "                loss = criterion(decoder_output, reference_cell_target[:, seq_idx])\n",
    "\n",
    "                decoder_output, decoder_hidden = decoder(decoder_output.view(BATCH_SIZE, 1),\n",
    "                                                         reference_cell_present_target[:, seq_idx -1].view(BATCH_SIZE, 1),\n",
    "                                                         neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                         decoder_hidden)\n",
    "            model_target[seq_idx].append((ref_x, ref_y, decoder_output.detach().numpy()[0][0][0]))\n",
    "            \n",
    "        \n",
    "        #print(\"decoder_target {}\".format(decoder_output))\n",
    "        #print(\"model_target {}\".format(model_target))\n",
    "    #print(decoder_output)\n",
    "    ################################\n",
    "    # DISPLAY\n",
    "    #################################\n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    cell_loads = cells_load_seq[screen_draw_idx]\n",
    "\n",
    "    if (screen_draw_idx < INPUT_SCREEN_COUNT) or (show_labels and screen_draw_idx >= INPUT_SCREEN_COUNT):\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "    else:\n",
    "        model_loads = model_target[screen_draw_idx - INPUT_SCREEN_COUNT]\n",
    "        for cell in model_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "        \n",
    "        # Update all cell loads\n",
    "        for i, cells in enumerate(cells_seq):\n",
    "            cells_load_seq[i] = load.calculate_cell_load(cells, loads)\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if show_labels:\n",
    "                show_labels = False\n",
    "            else:\n",
    "                show_labels = True\n",
    "                print(model_target[-1])\n",
    "                print(load_cells_seq_target[-1])\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.525749309424311\n",
      "tensor([[[ 0.4217,  0.1505]],\n",
      "\n",
      "        [[ 0.0130, -0.2582]]], grad_fn=<SubBackward0>)\n",
      "3.6756270584464072\n",
      "tensor([[[-0.6696, -0.1308]],\n",
      "\n",
      "        [[-0.7274, -0.1885]]], grad_fn=<SubBackward0>)\n",
      "3.106605948504992\n",
      "tensor([[[-0.1177, -4.3496]],\n",
      "\n",
      "        [[ 1.4640, -2.7679]]], grad_fn=<SubBackward0>)\n",
      "3.338417785162106\n",
      "tensor([[[-2.2205,  2.7795]],\n",
      "\n",
      "        [[-4.7280,  0.2720]]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-16efdb26b057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m                                                      \u001b[0mneighbourhood_influence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                                                      encoder_hidden)\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_cell_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mTEACHER_FORCING_PROB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             decoder_output, decoder_hidden = decoder(reference_cell_target[:, seq_idx - 1].view(BATCH_SIZE, 1),\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "INPUT_SEQ_LEN = 5\n",
    "TARGET_SEQ_LEN = 5\n",
    "HIDDEN_SIZE = 32\n",
    "# TODO fix BATCH_SIZE > 1 is bugged.\n",
    "BATCH_SIZE = 2\n",
    "TEACHER_FORCING_PROB = 0.5\n",
    "LEARNING_RATE = 1e-3\n",
    "PRINT_LOSS_EVERY = 1000\n",
    "neighbourhood_fully_connected = NeighbourhoodFullyConnected(2, 1, 16, 16)\n",
    "neighbourhood_fully_connected_decoder = NeighbourhoodFullyConnectedDecoder(2, 16, 16)\n",
    "encoder = EncoderRNN(1 + 1 + 16, HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(18, HIDDEN_SIZE)\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,5),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.33, 0.66\n",
    "                                                                                                                    ])\n",
    "dataloader = DataLoader(cell_load_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "parameters = (list(neighbourhood_fully_connected.parameters()) + \n",
    "                       list(neighbourhood_fully_connected_decoder.parameters()) +\n",
    "                       list(encoder.parameters()) +\n",
    "                       list(decoder.parameters()))\n",
    "\n",
    "optimizer = optim.Adam(parameters\n",
    "                       , lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "avg_loss_window = np.zeros(PRINT_LOSS_EVERY)\n",
    "avg_loss_window_idx = 0\n",
    "\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    reference_cell_input =  data[0]\n",
    "    reference_cell_present_input = data[1]\n",
    "    neighbourhood_cell_rel_input = data[2]\n",
    "    neighbourhood_cell_load_input = data[3]\n",
    "    reference_cell_target = data[4]\n",
    "    reference_cell_present_target = data[5]\n",
    "    neighbourhood_cell_rel_target = data[6]\n",
    "    optimizer.zero_grad()\n",
    "    for seq_idx in range(reference_cell_input.size(1)):\n",
    "        neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "        for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "            output = neighbourhood_fully_connected(neighbourhood_cell_rel_input[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2),\n",
    "                                          neighbourhood_cell_load_input[:,seq_idx, neighbourhood_cell_idx].view(BATCH_SIZE, 1))\n",
    "            neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "        # Concatonate neighbourhood with reference cell time series.\n",
    "        cat_ref_input = (torch.cat((reference_cell_input[:, seq_idx].view(BATCH_SIZE, 1),\n",
    "                                            reference_cell_present_input[:, seq_idx].view(BATCH_SIZE, 1)), dim=1))\n",
    "        encoder_input = torch.cat((cat_ref_input , neighbourhood_influence), dim=1).view(BATCH_SIZE, 1, 1 + 1+ 16)\n",
    "        if seq_idx==0:\n",
    "            encoder_hidden = torch.zeros(1, BATCH_SIZE, HIDDEN_SIZE, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "    \n",
    "    for seq_idx in range(reference_cell_target.size(1)):\n",
    "        neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "\n",
    "        for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "            output = neighbourhood_fully_connected_decoder(neighbourhood_cell_rel_target[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2))\n",
    "            neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "\n",
    "        if seq_idx==0:\n",
    "            decoder_output, decoder_hidden = decoder(reference_cell_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                     reference_cell_present_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                     neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                     encoder_hidden)\n",
    "            loss = criterion(decoder_output, reference_cell_target[:, seq_idx])\n",
    "        if random.random() > TEACHER_FORCING_PROB:\n",
    "            decoder_output, decoder_hidden = decoder(reference_cell_target[:, seq_idx - 1].view(BATCH_SIZE, 1),\n",
    "                                                     reference_cell_present_target[:, seq_idx -1].view(BATCH_SIZE, 1),\n",
    "                                                     neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                     decoder_hidden)\n",
    "        else:\n",
    "            decoder_output, decoder_hidden = decoder(decoder_output.view(BATCH_SIZE, 1),\n",
    "                                                     reference_cell_present_target[:, seq_idx -1].view(BATCH_SIZE, 1),\n",
    "                                                     neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                     decoder_hidden)\n",
    "            loss += criterion(decoder_output, reference_cell_target[:, seq_idx])\n",
    "\n",
    "            \n",
    "    loss.backward()\n",
    "    avg_loss_window[avg_loss_window_idx] = loss.data\n",
    "    if avg_loss_window_idx >= PRINT_LOSS_EVERY - 1:\n",
    "        avg_loss_window_idx = 0\n",
    "        print(avg_loss_window.mean())\n",
    "        #for param in parameters:\n",
    "            #print(param.shape)\n",
    "            #print(param.grad.data)\n",
    "        print(decoder_output - reference_cell_target[:, seq_idx])\n",
    "    else:\n",
    "        avg_loss_window_idx += 1         \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9fc3127cea58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMOUSEBUTTONUP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mdraw_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtarget_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_draw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mdisplay_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "screen_draw_idx = 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "\n",
    "def add_cell_if_not_exists(new_cell, cells):\n",
    "    cell_already_exists = False\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == new_cell[0] and cell[1] == new_cell[1]:\n",
    "            cell_already_exists = True\n",
    "            break\n",
    "    if not cell_already_exists:\n",
    "        cells.append(new_cell)\n",
    "    return cells\n",
    "\n",
    "def remove_cell_if_exists(remove_cell, cells):\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == remove_cell[0] and cell[1] == remove_cell[1]:\n",
    "            cells.pop(i)\n",
    "            break\n",
    "    return cells\n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    if len(cells) > 0:\n",
    "        cell_loads = load.calculate_cell_load(cells, loads)\n",
    "        #print(cell_loads)\n",
    "        #print(loads)\n",
    "\n",
    "\n",
    "\n",
    "        # Update screen\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "        \n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if freeze:\n",
    "                freeze = False\n",
    "            else:\n",
    "                freeze = True\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
