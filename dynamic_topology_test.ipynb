{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import random\n",
    "import pygame\n",
    "import math\n",
    "import torch\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import load\n",
    "from models import EncoderRNN, DecoderRNN, NeighbourhoodFullyConnected, NeighbourhoodFullyConnectedDecoder, SimpleEnd2End\n",
    "import load_topology_dataset\n",
    "from load_topology_dataset import MAX_CELL_COUNT, MIN_CELL_COUNT, IMAGE_SIZE\n",
    "device = \"cpu\"\n",
    "writer = SummaryWriter('runs/exp-1')\n",
    "writer3 = SummaryWriter(comment='3x learning rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplifying Assumptions\n",
    "1. No multiple carriers.\n",
    "2. Locations of loads and cells discretized to grid of resolution IMAGE_SIZE\n",
    "3. Cells are not limited by capacity\n",
    "4. Distribution of load follows inverse square of distance.\n",
    "5. Cells are omnidirectional.\n",
    "6. Load is constant.\n",
    "7. Only a maximum of 1 cell changes (addition or removal) at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 12, 0.6709275647328745), (31, 0, 0.3290724352671256)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loads = ((1,12), (22, 22))\n",
    "test_loads = [(1,12)]\n",
    "test_cells = [(2, 12), (31, 0)]\n",
    "load.calculate_cell_load(cells=test_cells, loads=test_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "PIXELS = 640\n",
    "LEFT = 1\n",
    "RIGHT = 3\n",
    "INPUT_SCREEN_COUNT = 1\n",
    "TARGET_SCREEN_COUNT = 1\n",
    "SCREEN_COUNT = INPUT_SCREEN_COUNT + TARGET_SCREEN_COUNT\n",
    "\n",
    "PIXELS_PER_BLOCK = int(PIXELS / IMAGE_SIZE)\n",
    "SCALE_ARR = np.ones((PIXELS_PER_BLOCK, PIXELS_PER_BLOCK, 1))\n",
    "print(PIXELS_PER_BLOCK)\n",
    "\n",
    "load_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "load_screen[1,12, 0] = 255\n",
    "load_screen[22,22, 0] = 255\n",
    "loads = [(1, 12), (22, 22)]\n",
    "block_img = np.kron(load_screen, SCALE_ARR)\n",
    "\n",
    "screen = pygame.display.set_mode((PIXELS, PIXELS))\n",
    "screens = []\n",
    "\n",
    "#for i in range(SCREEN_COUNT):\n",
    "##    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "#    screens.append(screen_draw)\n",
    "\n",
    "\n",
    "screen_draw_idx = 0\n",
    "\n",
    "\n",
    "draw_on = False\n",
    "last_pos = (0, 0)\n",
    "color = (255, 128, 0)\n",
    "radius = 10\n",
    "device = \"cpu\"\n",
    "\n",
    "block_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "model_screen = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "frame = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"abc\", \"def\", \"ghi\", \"jkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ghi', 'jkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell_if_not_exists(new_cell, cells):\n",
    "    cell_already_exists = False\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == new_cell[0] and cell[1] == new_cell[1]:\n",
    "            cell_already_exists = True\n",
    "            break\n",
    "    if not cell_already_exists:\n",
    "        cells.append(new_cell)\n",
    "    return cells\n",
    "\n",
    "def remove_cell_if_exists(remove_cell, cells):\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == remove_cell[0] and cell[1] == remove_cell[1]:\n",
    "            cells.pop(i)\n",
    "            break\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 7, 2.2508202)]\n",
      "[(8, 7, 2.0)]\n",
      "[(8, 7, 2.2508202), (11, 9, 0.49912065)]\n",
      "[(8, 7, 0.9851221980588887), (11, 9, 1.0148778019411113)]\n",
      "[(8, 7, 2.2508202), (11, 9, 0.49912065), (21, 5, 0.51507616)]\n",
      "[(8, 7, 0.6744800448818367), (11, 9, 0.6936017772688059), (21, 5, 0.6319181778493574)]\n",
      "[(8, 7, 2.2508202), (11, 9, 0.49912065), (21, 5, 0.51507616)]\n",
      "[(8, 7, 0.6744800448818367), (11, 9, 0.6936017772688059), (21, 5, 0.6319181778493574)]\n",
      "[(8, 7, 2.2508202), (11, 9, 0.49912065), (21, 5, 0.51507616), (28, 3, 0.5170754)]\n",
      "[(8, 7, 0.5319204526870114), (11, 9, 0.5460169866657945), (21, 5, 0.49564661629542406), (28, 3, 0.4264159443517701)]\n",
      "[(8, 7, 2.2508202), (11, 9, 0.49912065), (21, 5, 0.51507616), (28, 3, 0.5170754), (30, 1, 0.519131)]\n",
      "[(8, 7, 0.4470683741420237), (11, 9, 0.45831489581031515), (21, 5, 0.4149254113794831), (28, 3, 0.356021635319663), (30, 1, 0.323669683348515)]\n",
      "[(8, 7, 2.2508202), (11, 9, 0.49912065), (21, 5, 0.51507616), (28, 3, 0.5170754), (30, 1, 0.519131)]\n",
      "[(8, 7, 0.4470683741420237), (11, 9, 0.45831489581031515), (21, 5, 0.4149254113794831), (28, 3, 0.356021635319663), (30, 1, 0.323669683348515)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-368f937b58cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mseq_idx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;31m#print(\"encoder_hidden {}\".format(encoder_hidden))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/dynamic_topology/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "screen_draw_idx = 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "cells_load_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "BATCH_SIZE=1\n",
    "show_labels = True\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ##############################\n",
    "    # Use model to forecast future load\n",
    "    ##############################\n",
    "    load_cells_seq_input = cells_load_seq[:INPUT_SCREEN_COUNT]\n",
    "    load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "    \n",
    "    model_target = [list() for i in range(TARGET_SCREEN_COUNT)]\n",
    "    for reference_cell in cells_seq[-1]:\n",
    "        #print(reference_cell)\n",
    "        ref_x, ref_y = reference_cell[0], reference_cell[1]\n",
    "        reference_cell_input = np.zeros((INPUT_SCREEN_COUNT))\n",
    "        reference_cell_present_input = np.zeros((INPUT_SCREEN_COUNT))\n",
    "        neighbourhood_cell_rel_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT, 2))\n",
    "        neighbourhood_cell_load_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT))\n",
    "        neighbourhood_cell_present_input = np.zeros((INPUT_SCREEN_COUNT, MAX_CELL_COUNT))\n",
    "        for seq_idx in range(INPUT_SCREEN_COUNT):\n",
    "            reference_cell_active = False\n",
    "            cell_idx = 0\n",
    "            for cell in load_cells_seq_input[seq_idx]:\n",
    "                current_x = cell[0]\n",
    "                current_y = cell[1]\n",
    "                current_load = cell[2]\n",
    "                # If not reference cell add to neighbourhood\n",
    "                if not (current_x == ref_x and current_y == ref_y):\n",
    "                    # neighbourhood normalized by dividing by IMAGE_SIZE.\n",
    "                    # Subtract from 1 since cells that are closes have greated influence.\n",
    "                    #print(\"seq_idx {}\".format(seq_idx))\n",
    "                    #print(\"cell_idx {}\".format(cell_idx))\n",
    "                    neighbourhood_cell_rel_input[seq_idx, cell_idx, 0] = 1. - (ref_x - current_x) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_rel_input[seq_idx, cell_idx, 1] = 1. - (ref_y - current_y) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_load_input[seq_idx, cell_idx] = current_load\n",
    "                    cell_idx += 1\n",
    "                else:\n",
    "                    # print(\"ref cell\")\n",
    "                    reference_cell_input[seq_idx] = current_load\n",
    "                    reference_cell_active = True\n",
    "            if reference_cell_active:\n",
    "                reference_cell_present_input[seq_idx] = 1.0\n",
    "\n",
    "        load_cells_seq_target = cells_load_seq[INPUT_SCREEN_COUNT:]\n",
    "        reference_cell_present_target = np.zeros((TARGET_SCREEN_COUNT))\n",
    "        neighbourhood_cell_rel_target = np.zeros((TARGET_SCREEN_COUNT, MAX_CELL_COUNT, 2))\n",
    "\n",
    "\n",
    "        for seq_idx in range(TARGET_SCREEN_COUNT):\n",
    "            reference_cell_active = False\n",
    "            cell_idx = 0\n",
    "            for cell in load_cells_seq_target[seq_idx]:\n",
    "                current_x = cell[0]\n",
    "                current_y = cell[1]\n",
    "                current_load = cell[2]\n",
    "                #print(current_load)\n",
    "                # If not reference cell add to neighbourhood\n",
    "                if not (current_x == ref_x and current_y == ref_y):\n",
    "                    # neighbourhood normalized by dividing by IMAGE_SIZE.\n",
    "                    # Subtract from 1 since cells that are closes have greated influence.\n",
    "                    neighbourhood_cell_rel_target[seq_idx, cell_idx, 0] = 1. - abs(ref_x - current_x) / IMAGE_SIZE\n",
    "                    neighbourhood_cell_rel_target[seq_idx, cell_idx, 1] = 1. - abs(ref_y - current_y) / IMAGE_SIZE\n",
    "                    cell_idx += 1\n",
    "                else:\n",
    "                    reference_cell_active = True\n",
    "            if reference_cell_active:\n",
    "                reference_cell_present_target[seq_idx] = 1.0\n",
    "\n",
    "        reference_cell_input = torch.tensor(reference_cell_input, dtype=torch.float32).unsqueeze(0)\n",
    "        reference_cell_present_input = torch.tensor(reference_cell_present_input, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_rel_input = torch.tensor(neighbourhood_cell_rel_input, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_load_input = torch.tensor(neighbourhood_cell_load_input, dtype=torch.float32).unsqueeze(0)\n",
    "        reference_cell_present_target = torch.tensor(reference_cell_present_target, dtype=torch.float32).unsqueeze(0)\n",
    "        neighbourhood_cell_rel_target = torch.tensor(neighbourhood_cell_rel_target, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        for seq_idx in range(INPUT_SCREEN_COUNT):\n",
    "            neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "            for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "                output = neighbourhood_fully_connected(neighbourhood_cell_rel_input[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2),\n",
    "                                              neighbourhood_cell_load_input[:,seq_idx, neighbourhood_cell_idx].view(BATCH_SIZE, 1))\n",
    "                neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "            # Concatonate neighbourhood with reference cell time series.\n",
    "            cat_ref_input = (torch.cat((reference_cell_input[:, seq_idx].view(BATCH_SIZE, 1),\n",
    "                                                reference_cell_present_input[:, seq_idx].view(BATCH_SIZE, 1)), dim=1))\n",
    "            encoder_input = torch.cat((cat_ref_input , neighbourhood_influence), dim=1).view(BATCH_SIZE, 1, 1 + 1+ 16)\n",
    "            if seq_idx==0:\n",
    "                encoder_hidden = torch.zeros(2, BATCH_SIZE, HIDDEN_SIZE, device=device)\n",
    "            encoder_output, encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "        #print(\"encoder_hidden {}\".format(encoder_hidden))\n",
    "\n",
    "        for seq_idx in range(TARGET_SCREEN_COUNT):\n",
    "            neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "\n",
    "            #print(\"reference_cell_input {}\".format(reference_cell_input))\n",
    "            \n",
    "            for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "                output = neighbourhood_fully_connected_decoder(neighbourhood_cell_rel_target[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2))\n",
    "                neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "\n",
    "            #print(\"output {}\".format(output))\n",
    "            #print(\"neighbourhood_influence {}\".format(neighbourhood_influence))\n",
    "            if seq_idx==0:\n",
    "                decoder_output, decoder_hidden = decoder(reference_cell_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                         reference_cell_present_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                         neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                         encoder_hidden)\n",
    "                loss = criterion(decoder_output, reference_cell_target[:, seq_idx])\n",
    "\n",
    "                decoder_output, decoder_hidden = decoder(decoder_output.view(BATCH_SIZE, 1),\n",
    "                                                         reference_cell_present_target[:, seq_idx -1].view(BATCH_SIZE, 1),\n",
    "                                                         neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                         decoder_hidden)\n",
    "            model_target[seq_idx].append((ref_x, ref_y, decoder_output.detach().numpy()[0][0][0]))\n",
    "            \n",
    "        \n",
    "        #print(\"decoder_target {}\".format(decoder_output))\n",
    "        #print(\"model_target {}\".format(model_target))\n",
    "    #print(decoder_output)\n",
    "    ################################\n",
    "    # DISPLAY\n",
    "    #################################\n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    cell_loads = cells_load_seq[screen_draw_idx]\n",
    "\n",
    "    if (screen_draw_idx < INPUT_SCREEN_COUNT) or (show_labels and screen_draw_idx >= INPUT_SCREEN_COUNT):\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "    else:\n",
    "        model_loads = model_target[screen_draw_idx - INPUT_SCREEN_COUNT]\n",
    "        for cell in model_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "        \n",
    "        # Update all cell loads\n",
    "        for i, cells in enumerate(cells_seq):\n",
    "            cells_load_seq[i] = load.calculate_cell_load(cells, loads)\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if show_labels:\n",
    "                show_labels = False\n",
    "            else:\n",
    "                show_labels = True\n",
    "                print(model_target[-1])\n",
    "                print(load_cells_seq_target[-1])\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1045,  0.4002, -0.1971,  0.1176, -0.1599, -0.0181, -0.1915]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4999999999999998"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.142857142857143 * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('input_layer', Sequential(\n",
       "  (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       ")), ('output_layer', Sequential(\n",
       "  (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(32, 1)\n",
      "      %1 : Float(32, 1)\n",
      "      %2 : Float(32, 12)\n",
      "      %3 : Float(32, 6)\n",
      "      %4 : Float(32, 12)\n",
      "      %5 : Float(64, 32)\n",
      "      %6 : Float(64)\n",
      "      %7 : Float(1, 64)\n",
      "      %8 : Float(1)) {\n",
      "  %9 : Float(32, 2) = onnx::Concat[axis=1](%0, %1), scope: SimpleEnd2End\n",
      "  %10 : Float(32, 14) = onnx::Concat[axis=1](%9, %2), scope: SimpleEnd2End\n",
      "  %11 : Float(32, 20) = onnx::Concat[axis=1](%10, %3), scope: SimpleEnd2End\n",
      "  %12 : Float(32, 32) = onnx::Concat[axis=1](%11, %4), scope: SimpleEnd2End\n",
      "  %13 : Float(32!, 64!) = onnx::Transpose[perm=[1, 0]](%5), scope: SimpleEnd2End/Sequential[input_layer]/Linear[0]\n",
      "  %14 : Float(32, 64) = onnx::Gemm[alpha=1, beta=1](%12, %13, %6), scope: SimpleEnd2End/Sequential[input_layer]/Linear[0]\n",
      "  %15 : Float(32, 64) = onnx::Relu(%14), scope: SimpleEnd2End/Sequential[input_layer]/ReLU[1]\n",
      "  %16 : Float(64!, 1!) = onnx::Transpose[perm=[1, 0]](%7), scope: SimpleEnd2End/Sequential[output_layer]/Linear[0]\n",
      "  %17 : Float(32, 1) = onnx::Gemm[alpha=1, beta=1](%15, %16, %8), scope: SimpleEnd2End/Sequential[output_layer]/Linear[0]\n",
      "  return (%17);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-b15a4b24f618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mavg_loss_window_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mreference_cell_input\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mreference_cell_present_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "INPUT_SEQ_LEN = 1\n",
    "TARGET_SEQ_LEN = 1\n",
    "HIDDEN_SIZE = 32\n",
    "# TODO fix BATCH_SIZE > 1 is bugged.\n",
    "BATCH_SIZE = 32\n",
    "TEACHER_FORCING_PROB = 0.5\n",
    "LEARNING_RATE = 1e-3\n",
    "PRINT_LOSS_EVERY = 100\n",
    "model = SimpleEnd2End()\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,5),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.33, 0.66\n",
    "                                                                                                                    ], seed=0)\n",
    "dataloader = DataLoader(cell_load_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=2)\n",
    "\n",
    "parameters = (list(model.parameters()))\n",
    "\n",
    "optimizer = optim.SGD(parameters\n",
    "                       ,lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "avg_loss_window = np.zeros(PRINT_LOSS_EVERY)\n",
    "avg_loss_window_idx = 0\n",
    "\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    reference_cell_input =  data[0].view(BATCH_SIZE, 1)\n",
    "    reference_cell_present_input = data[1].view(BATCH_SIZE, 1)\n",
    "    neighbourhood_cell_rel_input = data[2].view(BATCH_SIZE, 12)\n",
    "    neighbourhood_cell_load_input = data[3].view(BATCH_SIZE, 6)\n",
    "    reference_cell_target = data[4].view(BATCH_SIZE, 1)\n",
    "    reference_cell_present_target = data[5].view(BATCH_SIZE, 1)\n",
    "    neighbourhood_cell_rel_target = data[6].view(BATCH_SIZE, 12)\n",
    "    #print(reference_cell_input) \n",
    "    \n",
    "    if batch_idx == 0:\n",
    "        writer.add_graph(model, (reference_cell_input, reference_cell_present_input,\n",
    "    neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_rel_target), True)\n",
    "    \n",
    "    # Manual input\n",
    "    optimizer.zero_grad()\n",
    "    #print(reference_cell_input.shape)\n",
    "    output = model(reference_cell_input, reference_cell_present_input,\n",
    "    neighbourhood_cell_rel_input, neighbourhood_cell_load_input, neighbourhood_cell_rel_target)\n",
    "    loss = criterion(output, reference_cell_target[:, 0])\n",
    "    #print(\"target:{}\".format(reference_cell_target[:, 0]))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    avg_loss_window[avg_loss_window_idx] = loss.data\n",
    "    #writer.add_histogram('parameter_0', parameters[0].data.numpy(), batch_idx)\n",
    "    #writer.add_histogram('parameter_1', parameters[1].data.numpy(), batch_idx)\n",
    "    #writer.add_histogram('parameter_2', parameters[2].data.numpy(), batch_idx)\n",
    "    #writer.add_histogram('parameter_3', parameters[3].data.numpy(), batch_idx)\n",
    "    if avg_loss_window_idx >= PRINT_LOSS_EVERY - 1:\n",
    "        writer.add_scalar('loss', loss.data.numpy(), batch_idx)\n",
    "        plot_parameters(model)\n",
    "        avg_loss_window_idx = 0\n",
    "        #print(avg_loss_window.mean())\n",
    "        #print(list(decoder.parameters())[0].grad.data)\n",
    "        #for param in parameters:\n",
    "        #    print(param.shape)\n",
    "        #    print(param.grad.data)\n",
    "        # print(\"decoder_output {}\".format(decoder_output))\n",
    "        #print(decoder_output - reference_cell_target[:, seq_idx])\n",
    "    else:\n",
    "        avg_loss_window_idx += 1         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DynamicTopologyModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0d69a3b87a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m DynamicTopologyModel(neighbourhood_hidden_size=32, neighbourhood_cell_count=6,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      neighbourhood_output_size=16, gru_layers=2, teacher_forcing_probability=1.0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DynamicTopologyModel' is not defined"
     ]
    }
   ],
   "source": [
    "DynamicTopologyModel(neighbourhood_hidden_size=32, neighbourhood_cell_count=6,\n",
    "                     neighbourhood_output_size=16, gru_layers=2, teacher_forcing_probability=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3525], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1045,  0.4002, -0.1971,  0.1176, -0.1599, -0.0181, -0.1915]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0.5222], requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d854956/personal/dynamic_topology/models.py:57: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  print(neighbourhood_rel_hidden_val.shape)\n",
      "/Users/d854956/personal/dynamic_topology/models.py:59: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  print(neighbourhood_load_hidden_val.shape)\n",
      "/Users/d854956/personal/dynamic_topology/models.py:61: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  print(neighbourhood_rel_hidden_output.shape)\n",
      "/Users/d854956/personal/dynamic_topology/models.py:63: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  print(neighbourhood_load_hidden_output.shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([32, 16])\n",
      "graph(%input.1 : Float(32!, 2)\n",
      "      %input.3 : Float(32!, 1)\n",
      "      %2 : Float(32, 2)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32, 1)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(16, 32)\n",
      "      %7 : Float(16)\n",
      "      %8 : Float(16, 32)\n",
      "      %9 : Float(16)) {\n",
      "  %10 : Float(2!, 32!) = onnx::Transpose[perm=[1, 0]](%2), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %11 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.1, %10, %3), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/Linear[0]\n",
      "  %12 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%11), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_input_layer]/LeakyReLU[1]\n",
      "  %13 : Float(1!, 32) = onnx::Transpose[perm=[1, 0]](%4), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %14 : Float(32, 32) = onnx::Gemm[alpha=1, beta=1](%input.3, %13, %5), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/Linear[0]\n",
      "  %15 : Float(32, 32) = onnx::LeakyRelu[alpha=0.01](%14), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_input_layer]/LeakyReLU[1]\n",
      "  %16 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%6), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %17 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%12, %16, %7), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Linear[0]\n",
      "  %18 : Float(32, 16) = onnx::Sigmoid(%17), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_rel_hidden_layer]/Sigmoid[1]\n",
      "  %19 : Float(32!, 16!) = onnx::Transpose[perm=[1, 0]](%8), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %20 : Float(32, 16) = onnx::Gemm[alpha=1, beta=1](%15, %19, %9), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/Linear[0]\n",
      "  %21 : Float(32, 16) = onnx::LeakyRelu[alpha=0.01](%20), scope: NeighbourhoodFullyConnected/Sequential[neighbourhood_load_hidden_layer]/LeakyReLU[1]\n",
      "  %22 : Float(32, 16) = onnx::Mul(%18, %21), scope: NeighbourhoodFullyConnected\n",
      "  return (%22);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6fa3a1ca63b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Concatonate neighbourhood with reference cell time series.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         writer.add_graph(neighbourhood_fully_connected, (neighbourhood_cell_rel_input[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2),\n\u001b[0;32m---> 49\u001b[0;31m                                           neighbourhood_cell_load_input[:,seq_idx, neighbourhood_cell_idx].view(BATCH_SIZE, 1)), True)\n\u001b[0m\u001b[1;32m     50\u001b[0m         cat_ref_input = (torch.cat((reference_cell_input[:, seq_idx].view(BATCH_SIZE, 1),\n\u001b[1;32m     51\u001b[0m                                             reference_cell_present_input[:, seq_idx].view(BATCH_SIZE, 1)), dim=1))\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add_graph() only supports PyTorch v0.2.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorboardX/pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, omit_useless_nodes)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mlist_of_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momit_useless_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=\"/device:CPU:0\",\n\u001b[1;32m    242\u001b[0m                                                                             node_stats=node_stats)]))\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorboardX/pytorch_graph.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(graph, args, omit_useless_nodes)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mNode_py_IO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mnodes_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_namespace_from_OP_to_IO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnodes_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorboardX/pytorch_graph.py\u001b[0m in \u001b[0;36mto_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m                                     \u001b[0moutputsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                                     \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                                     attributes=v.attributes))\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorSize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorSize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume data is float32, only parameter is counted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorboardX/proto_graph.py\u001b[0m in \u001b[0;36mNode_proto\u001b[0;34m(name, op, input, dtype, shape, outputsize, attributes)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAttrValue_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_listener_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNullMessageListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener_for_children\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetFieldByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "INPUT_SEQ_LEN = 1\n",
    "TARGET_SEQ_LEN = 1\n",
    "HIDDEN_SIZE = 32\n",
    "# TODO fix BATCH_SIZE > 1 is bugged.\n",
    "BATCH_SIZE = 32 \n",
    "TEACHER_FORCING_PROB = 0.5\n",
    "LEARNING_RATE = 1e-3\n",
    "PRINT_LOSS_EVERY = 100\n",
    "neighbourhood_fully_connected = NeighbourhoodFullyConnected(2, 1, 16, 16)\n",
    "neighbourhood_fully_connected_decoder = NeighbourhoodFullyConnectedDecoder(2, 16, 16)\n",
    "encoder = EncoderRNN(1 + 1 + 16, HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(18, HIDDEN_SIZE)\n",
    "cell_load_dataset = load_topology_dataset.LoadCellDataset(initial_cell_counts=(2, 5), initial_load_counts=(2,5),\n",
    "                                    input_seq_len=INPUT_SEQ_LEN, target_seq_len=TARGET_SEQ_LEN, network_mutate_prob=[0.33, 0.66\n",
    "                                                                                                                    ])\n",
    "dataloader = DataLoader(cell_load_dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "parameters = (list(neighbourhood_fully_connected.parameters()) + \n",
    "                       list(neighbourhood_fully_connected_decoder.parameters()) +\n",
    "                       list(encoder.parameters()) +\n",
    "                       list(decoder.parameters()))\n",
    "#parameters = (list(neighbourhood_fully_connected.parameters()) + \n",
    "#                       list(encoder.parameters()))\n",
    "\n",
    "optimizer = optim.Adam(parameters\n",
    "                       , lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "avg_loss_window = np.zeros(PRINT_LOSS_EVERY)\n",
    "avg_loss_window_idx = 0\n",
    "\n",
    "for batch_idx, data in enumerate(dataloader):\n",
    "    reference_cell_input =  data[0]\n",
    "    reference_cell_present_input = data[1]\n",
    "    neighbourhood_cell_rel_input = data[2]\n",
    "    neighbourhood_cell_load_input = data[3]\n",
    "    reference_cell_target = data[4]\n",
    "    reference_cell_present_target = data[5]\n",
    "    neighbourhood_cell_rel_target = data[6]\n",
    "    optimizer.zero_grad()\n",
    "    for seq_idx in range(reference_cell_input.size(1)):\n",
    "        neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "        for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "            output = neighbourhood_fully_connected(neighbourhood_cell_rel_input[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2),\n",
    "                                          neighbourhood_cell_load_input[:,seq_idx, neighbourhood_cell_idx].view(BATCH_SIZE, 1))\n",
    "            neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "        # Concatonate neighbourhood with reference cell time series.\n",
    "        writer.add_graph(neighbourhood_fully_connected, (neighbourhood_cell_rel_input[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2),\n",
    "                                          neighbourhood_cell_load_input[:,seq_idx, neighbourhood_cell_idx].view(BATCH_SIZE, 1)), True)\n",
    "        cat_ref_input = (torch.cat((reference_cell_input[:, seq_idx].view(BATCH_SIZE, 1),\n",
    "                                            reference_cell_present_input[:, seq_idx].view(BATCH_SIZE, 1)), dim=1))\n",
    "        encoder_input = torch.cat((cat_ref_input , neighbourhood_influence), dim=1).view(BATCH_SIZE, 1, 1 + 1+ 16)\n",
    "        if seq_idx==0:\n",
    "            encoder_hidden = torch.zeros(2, BATCH_SIZE, HIDDEN_SIZE, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "        #if seq_idx==0:\n",
    "            #loss = criterion(torch.rand(32, 128), encoder_output)\n",
    "        #else:\n",
    "            ##########################\n",
    "            # DELETE ME!\n",
    "            #########################\n",
    "            #loss += criterion(torch.rand(32, 128), encoder_output)\n",
    "    #avg_loss_window[avg_loss_window_idx] = loss.data\n",
    "\n",
    "       \n",
    "\n",
    "    #loss.backward()\n",
    "    \n",
    "    #if avg_loss_window_idx >= PRINT_LOSS_EVERY - 1:\n",
    "        #avg_loss_window_idx = 0\n",
    "        #print(avg_loss_window.mean())\n",
    "        #for param in parameters:\n",
    "            #print(param.shape)\n",
    "            #print(param.grad.data)\n",
    "    #else:\n",
    "        #avg_loss_window_idx += 1  \n",
    "    #optimizer.step()\n",
    "\n",
    "    ##########################\n",
    "    # DELETE ME!\n",
    "    #########################\n",
    "    \n",
    "    for seq_idx in range(reference_cell_target.size(1)):\n",
    "        neighbourhood_influence = torch.zeros(BATCH_SIZE, 16)\n",
    "\n",
    "        for neighbourhood_cell_idx in range(MAX_CELL_COUNT):\n",
    "            output = neighbourhood_fully_connected_decoder(neighbourhood_cell_rel_target[:,seq_idx, neighbourhood_cell_idx, :].view(BATCH_SIZE, 2))\n",
    "            neighbourhood_influence = torch.add(neighbourhood_influence, output)\n",
    "        #print(neighbourhood_influence)\n",
    "        # Feed in the last input in the sequence into the decoder and use the last encoder hidden state as the initial hidden state.\n",
    "        #print(reference_cell_input[:, -1])\n",
    "        #print(reference_cell_present_input[:, -1])\n",
    "        if seq_idx==0:\n",
    "            decoder_output, decoder_hidden = decoder(reference_cell_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                     reference_cell_present_input[:, -1].view(BATCH_SIZE, 1),\n",
    "                                                     neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                     encoder_hidden)\n",
    "            loss = criterion(decoder_output, reference_cell_target[:, seq_idx])\n",
    "        if random.random() > TEACHER_FORCING_PROB:\n",
    "            decoder_output, decoder_hidden = decoder(reference_cell_target[:, seq_idx - 1].view(BATCH_SIZE, 1),\n",
    "                                                     reference_cell_present_target[:, seq_idx -1].view(BATCH_SIZE, 1),\n",
    "                                                     neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                     decoder_hidden)\n",
    "        else:\n",
    "            decoder_output, decoder_hidden = decoder(decoder_output.view(BATCH_SIZE, 1),\n",
    "                                                     reference_cell_present_target[:, seq_idx -1].view(BATCH_SIZE, 1),\n",
    "                                                     neighbourhood_influence.view(BATCH_SIZE, 16),\n",
    "                                                     decoder_hidden)\n",
    "            loss += criterion(decoder_output, reference_cell_target[:, seq_idx])\n",
    "\n",
    "            \n",
    "    loss.backward()\n",
    "    avg_loss_window[avg_loss_window_idx] = loss.data\n",
    "    writer.add_scalar('loss', avg_loss_window.mean(), batch_idx)\n",
    "    writer.add_histogram('parameter_0', parameters[0].data.numpy(), batch_idx)\n",
    "    if avg_loss_window_idx >= PRINT_LOSS_EVERY - 1:\n",
    "        \n",
    "        avg_loss_window_idx = 0\n",
    "        print(avg_loss_window.mean())\n",
    "        #for param in parameters:\n",
    "            #print(param.shape)\n",
    "            #print(param.grad.data)\n",
    "        #print(decoder_output - reference_cell_target[:, seq_idx])\n",
    "    else:\n",
    "        avg_loss_window_idx += 1         \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50105333, -0.03621238],\n",
       "       [-0.6716445 ,  0.2170561 ],\n",
       "       [-0.07053212, -0.21118125],\n",
       "       [ 0.35602853,  0.3363651 ],\n",
       "       [-0.31223166,  0.35850143],\n",
       "       [-0.7075539 , -0.11176805],\n",
       "       [-0.03756676, -0.18710963],\n",
       "       [ 0.11037824,  0.351485  ],\n",
       "       [-0.48305982,  0.5724187 ],\n",
       "       [ 0.62445164,  0.148751  ],\n",
       "       [ 0.3769189 , -0.05743391],\n",
       "       [-0.16877972, -0.1388054 ],\n",
       "       [-0.3683863 ,  0.6243406 ],\n",
       "       [ 0.24089734, -0.33954647],\n",
       "       [ 0.3014789 , -0.16865112],\n",
       "       [-0.27933788, -0.1143957 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1148,  0.1018, -0.2019,  0.0415, -0.0409, -0.2270,  0.2182,  0.1528,\n",
       "         -0.0238,  0.0319, -0.0558, -0.0170,  0.0188, -0.0592,  0.0674,  0.1079,\n",
       "         -0.0682,  0.1211],\n",
       "        [-0.2490,  0.1737,  0.1887, -0.0509,  0.0821, -0.1362, -0.1827, -0.0332,\n",
       "         -0.0813,  0.1133, -0.1793, -0.1379,  0.0746,  0.0311, -0.0412,  0.0491,\n",
       "         -0.0063, -0.1207],\n",
       "        [-0.0639, -0.2160, -0.0790, -0.1887, -0.2419,  0.0460, -0.1359,  0.0479,\n",
       "         -0.2079,  0.0567, -0.2594, -0.2213,  0.0427,  0.0444, -0.0648,  0.1961,\n",
       "         -0.1447,  0.0390],\n",
       "        [-0.0062, -0.0581,  0.1298, -0.0125,  0.1165, -0.1581, -0.1394, -0.0580,\n",
       "         -0.1481,  0.1173, -0.1226, -0.0205, -0.0550, -0.1158, -0.1596, -0.1481,\n",
       "         -0.1614, -0.0857],\n",
       "        [ 0.1030, -0.2071, -0.1594, -0.1416, -0.2311, -0.1790, -0.1107, -0.0542,\n",
       "          0.1006,  0.2105, -0.1977, -0.2460,  0.1470, -0.1744,  0.1268, -0.1630,\n",
       "          0.0480,  0.1013],\n",
       "        [-0.0702, -0.1749, -0.0296,  0.0748, -0.1055,  0.1554,  0.1268, -0.1687,\n",
       "          0.0858,  0.1282,  0.0314,  0.0086,  0.1732,  0.1919,  0.1080,  0.0994,\n",
       "         -0.0394, -0.2059],\n",
       "        [ 0.1724,  0.2240,  0.1845,  0.0456, -0.0330,  0.1032,  0.0513, -0.1425,\n",
       "         -0.0380, -0.1205,  0.0395,  0.1087, -0.0085, -0.1416,  0.1652,  0.1204,\n",
       "          0.0791, -0.2543],\n",
       "        [ 0.1226,  0.2658, -0.1532, -0.1819, -0.0477, -0.1281,  0.0473,  0.1865,\n",
       "         -0.0360, -0.0353,  0.0670, -0.1231, -0.0881, -0.0186,  0.2498, -0.1367,\n",
       "          0.0680, -0.0719],\n",
       "        [-0.1729,  0.2598, -0.1709,  0.2541,  0.1149, -0.0036, -0.0909,  0.1981,\n",
       "          0.2479,  0.1554, -0.1375, -0.1807, -0.0137, -0.0388, -0.0931,  0.0254,\n",
       "          0.2292,  0.1900],\n",
       "        [-0.0403, -0.0861,  0.1924, -0.0500,  0.1670, -0.0746, -0.0815,  0.0144,\n",
       "          0.2236,  0.1176,  0.0633, -0.0411, -0.1232, -0.1093, -0.0719, -0.1402,\n",
       "          0.0597, -0.2023],\n",
       "        [-0.2509, -0.1673, -0.2295,  0.0828,  0.1206, -0.0605,  0.2054, -0.0858,\n",
       "          0.0378,  0.1419,  0.0767, -0.1611,  0.1339,  0.0192,  0.0682, -0.1526,\n",
       "          0.1556,  0.2140],\n",
       "        [ 0.2563,  0.1774,  0.2578,  0.1337, -0.0923, -0.2268,  0.0351, -0.2571,\n",
       "          0.0886, -0.1588, -0.0151,  0.2573,  0.0430, -0.1371, -0.0918,  0.1866,\n",
       "          0.0233, -0.0926],\n",
       "        [ 0.1261, -0.0418, -0.1738, -0.0756,  0.1474, -0.0714,  0.1783,  0.1985,\n",
       "          0.1334, -0.0845, -0.1482,  0.1161, -0.2040,  0.2438, -0.0549,  0.2109,\n",
       "         -0.0004,  0.1053],\n",
       "        [ 0.0535,  0.1812,  0.0327,  0.0038, -0.1027, -0.0969, -0.1027,  0.0824,\n",
       "         -0.1232, -0.2323,  0.1994,  0.1370,  0.2419, -0.1437, -0.1458,  0.1487,\n",
       "          0.1050, -0.1990],\n",
       "        [-0.1741, -0.2473, -0.2255,  0.0387, -0.1294,  0.0325, -0.2696,  0.1072,\n",
       "          0.1354,  0.2581, -0.0606,  0.0392, -0.0416,  0.1418, -0.1708,  0.0512,\n",
       "         -0.2200, -0.1401],\n",
       "        [-0.2585, -0.2365,  0.1762, -0.1477, -0.0448, -0.1531, -0.2242,  0.2045,\n",
       "         -0.2378,  0.0741, -0.1168,  0.0725, -0.2575,  0.1111, -0.2110, -0.1631,\n",
       "          0.1162,  0.1177],\n",
       "        [-0.0352,  0.0096,  0.0623,  0.1057, -0.1177,  0.0753, -0.0468, -0.0356,\n",
       "         -0.0888,  0.1071, -0.0301, -0.1208, -0.0620, -0.1938, -0.0760,  0.0938,\n",
       "         -0.2147, -0.1829],\n",
       "        [ 0.0130, -0.0145, -0.1879,  0.1461, -0.0198, -0.0308,  0.1628, -0.2009,\n",
       "          0.1242, -0.1732, -0.2215,  0.0815, -0.1075, -0.1734,  0.0310,  0.0318,\n",
       "          0.2085,  0.0750],\n",
       "        [-0.2039,  0.0854, -0.1750,  0.0894, -0.0259, -0.2341, -0.2170,  0.0371,\n",
       "         -0.1606, -0.1285,  0.0765,  0.1035,  0.0470,  0.2266, -0.1039,  0.0291,\n",
       "          0.0243,  0.0426],\n",
       "        [ 0.0403,  0.1683, -0.1465, -0.2412, -0.1162,  0.0465, -0.2514,  0.2612,\n",
       "         -0.0178, -0.1487, -0.0727,  0.1455,  0.1716, -0.2209,  0.1032,  0.0100,\n",
       "         -0.2639, -0.1279],\n",
       "        [ 0.2393, -0.0307,  0.1888,  0.1123, -0.0976, -0.1397, -0.0262, -0.1019,\n",
       "          0.0603, -0.1485,  0.1051, -0.1760, -0.1749,  0.1296, -0.1199,  0.2654,\n",
       "          0.0026, -0.2047],\n",
       "        [ 0.1945, -0.1310,  0.0857,  0.1354,  0.0568, -0.1075, -0.0268, -0.1699,\n",
       "          0.0187,  0.0538,  0.0377, -0.1413,  0.1629,  0.2100,  0.2232,  0.2505,\n",
       "          0.0920,  0.0238],\n",
       "        [-0.0971,  0.0186,  0.0095,  0.1274,  0.1428,  0.2646, -0.2262,  0.0446,\n",
       "          0.1729, -0.0259,  0.0641, -0.1804,  0.1333, -0.2259, -0.1408,  0.1653,\n",
       "         -0.1190,  0.1547],\n",
       "        [ 0.2100,  0.2156,  0.1673,  0.0030,  0.0866, -0.1548,  0.1119, -0.1166,\n",
       "         -0.1423, -0.1712,  0.0845, -0.0020,  0.2393,  0.0207, -0.0658,  0.0148,\n",
       "         -0.1317,  0.1288],\n",
       "        [-0.1695,  0.2683,  0.2159, -0.0525,  0.1916, -0.2638,  0.0342, -0.2007,\n",
       "          0.0222, -0.2460,  0.0786,  0.0877,  0.1364,  0.0032,  0.1053, -0.0155,\n",
       "          0.0862, -0.0072],\n",
       "        [ 0.0882,  0.1074,  0.1251,  0.1669,  0.0730,  0.1230, -0.1879, -0.2061,\n",
       "         -0.0475, -0.0573,  0.0864, -0.1672,  0.0037,  0.0598,  0.0181, -0.1045,\n",
       "          0.1829, -0.1009],\n",
       "        [ 0.0067, -0.1649,  0.1563,  0.1912, -0.1771, -0.1273, -0.0267,  0.0142,\n",
       "         -0.0864, -0.2164, -0.2213, -0.2335, -0.0507, -0.1693,  0.0733, -0.1735,\n",
       "          0.1074, -0.2074],\n",
       "        [-0.1057, -0.0440,  0.1971, -0.1233, -0.1404, -0.2059,  0.1350, -0.1524,\n",
       "         -0.1796,  0.2093,  0.1245, -0.1474,  0.0513, -0.0045,  0.1823, -0.1182,\n",
       "         -0.1152,  0.0532],\n",
       "        [-0.0580, -0.1427,  0.0575,  0.2393, -0.0908, -0.0972, -0.0442,  0.0541,\n",
       "          0.0830,  0.0559, -0.0768,  0.0242,  0.0578,  0.2340, -0.1029,  0.2381,\n",
       "         -0.1185,  0.1720],\n",
       "        [ 0.1092, -0.0808,  0.0215, -0.1408,  0.2565, -0.2281,  0.0809,  0.0960,\n",
       "         -0.2041,  0.0729, -0.1531,  0.0906,  0.2196,  0.0272, -0.1544,  0.2318,\n",
       "          0.2193, -0.0214],\n",
       "        [-0.2159, -0.1486,  0.1679, -0.1592,  0.2012, -0.0491, -0.0741,  0.0454,\n",
       "         -0.0702,  0.0065, -0.2007,  0.1630, -0.2343,  0.1600, -0.2610,  0.1227,\n",
       "         -0.1180,  0.0068],\n",
       "        [ 0.1052,  0.0421,  0.0462,  0.1458, -0.0882,  0.0299,  0.0273, -0.0571,\n",
       "         -0.1164,  0.0369, -0.1826,  0.1721, -0.0381,  0.2041,  0.1375, -0.0991,\n",
       "          0.0626, -0.1991]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder.parameters())[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9fc3127cea58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMOUSEBUTTONUP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mdraw_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtarget_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_draw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mdisplay_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "screen_draw_idx = 0\n",
    "cells_seq = [list() for i in range(SCREEN_COUNT)]\n",
    "\n",
    "def add_cell_if_not_exists(new_cell, cells):\n",
    "    cell_already_exists = False\n",
    "\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == new_cell[0] and cell[1] == new_cell[1]:\n",
    "            cell_already_exists = True\n",
    "            break\n",
    "    if not cell_already_exists:\n",
    "        cells.append(new_cell)\n",
    "    return cells\n",
    "\n",
    "def remove_cell_if_exists(remove_cell, cells):\n",
    "    for i, cell in enumerate(cells):\n",
    "        if cell[0] == remove_cell[0] and cell[1] == remove_cell[1]:\n",
    "            cells.pop(i)\n",
    "            break\n",
    "    return cells\n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    screen_draw = pygame.Surface((PIXELS, PIXELS))\n",
    "    \n",
    "    #print(cells_seq)\n",
    "    cells = cells_seq[screen_draw_idx]\n",
    "    if len(cells) > 0:\n",
    "        cell_loads = load.calculate_cell_load(cells, loads)\n",
    "        #print(cell_loads)\n",
    "        #print(loads)\n",
    "\n",
    "\n",
    "\n",
    "        # Update screen\n",
    "        for cell in cell_loads:\n",
    "            color = (cell[2] * 1024) - 256\n",
    "            if color > 255:\n",
    "                color = 255\n",
    "            if color < 0:\n",
    "                color = 0\n",
    "            pygame.draw.rect(\n",
    "            screen_draw,\n",
    "            (color, 50, 0),\n",
    "            (\n",
    "                cell[0] * PIXELS_PER_BLOCK,\n",
    "                cell[1] * PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "                PIXELS_PER_BLOCK,\n",
    "            ),\n",
    "            )\n",
    "        \n",
    "\n",
    "    e = pygame.event.poll()\n",
    "\n",
    "\n",
    "    if e.type == pygame.QUIT:\n",
    "        raise StopIteration\n",
    "    if e.type == pygame.MOUSEBUTTONDOWN:\n",
    "        leftclick, middleclick, rightclick = pygame.mouse.get_pressed()\n",
    "        x, y = e.pos\n",
    "        x_cell= int(x / PIXELS_PER_BLOCK)\n",
    "        y_cell = int(y / PIXELS_PER_BLOCK)\n",
    "        if leftclick:\n",
    "            cells = add_cell_if_not_exists((x_cell, y_cell), cells)\n",
    "        elif rightclick:\n",
    "            cells = remove_cell_if_exists((x_cell, y_cell), cells)            \n",
    "        draw_on = True\n",
    "        # Update cells\n",
    "        cells_seq[screen_draw_idx] = cells\n",
    "    \n",
    "    if e.type == pygame.KEYDOWN:\n",
    "        if e.key == pygame.K_SPACE:\n",
    "            if freeze:\n",
    "                freeze = False\n",
    "            else:\n",
    "                freeze = True\n",
    "        if e.key ==  pygame.K_LEFT:\n",
    "            if screen_draw_idx > 0:\n",
    "                screen_draw_idx -= 1\n",
    "        if e.key ==  pygame.K_RIGHT:\n",
    "            if screen_draw_idx < SCREEN_COUNT - 1:\n",
    "                screen_draw_idx += 1\n",
    "    if e.type == pygame.MOUSEBUTTONUP:\n",
    "        draw_on = False\n",
    "    pygame.display.flip()\n",
    "    target_screen = pygame.surfarray.array3d(screen_draw)\n",
    "    display_img = block_img + target_screen\n",
    "    new_surf = pygame.pixelcopy.make_surface(display_img.astype(np.uint8))\n",
    "    screen.blit(new_surf, (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFF1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleFF1, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.input_layer = nn.Sequential(nn.Linear(input_size, hidden_size), nn.LeakyReLU())\n",
    "        self.output_layer = nn.Sequential(nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.input_layer(input)\n",
    "        output = self.output_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleFF(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MultipleFF, self).__init__()\n",
    "        self.model0 = SimpleFF1(input_size, hidden_size)\n",
    "        self.model1 = SimpleFF1(1, hidden_size)\n",
    "        self.output_activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.model0(input)\n",
    "        output = self.model1(output)\n",
    "        output = self.output_activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleff = MultipleFF(16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_values = torch.autograd.Variable(torch.ones(16), requires_grad=True)\n",
    "input_values = torch.ones(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0344], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleff(input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(16)\n",
      "      %1 : Float(32, 16)\n",
      "      %2 : Float(32)\n",
      "      %3 : Float(1, 32)\n",
      "      %4 : Float(1)) {\n",
      "  %5 : Float(16!, 32!) = onnx::Transpose[perm=[1, 0]](%1), scope: SimpleFF1/Sequential[input_layer]/Linear[0]\n",
      "  %6 : Float(32) = onnx::MatMul(%input.1, %5), scope: SimpleFF1/Sequential[input_layer]/Linear[0]\n",
      "  %7 : Float(32) = onnx::Add(%6, %2), scope: SimpleFF1/Sequential[input_layer]/Linear[0]\n",
      "  %8 : Float(32) = onnx::LeakyRelu[alpha=0.01](%7), scope: SimpleFF1/Sequential[input_layer]/LeakyReLU[1]\n",
      "  %9 : Float(32!, 1!) = onnx::Transpose[perm=[1, 0]](%3), scope: SimpleFF1/Sequential[output_layer]/Linear[0]\n",
      "  %10 : Float(1) = onnx::MatMul(%8, %9), scope: SimpleFF1/Sequential[output_layer]/Linear[0]\n",
      "  %11 : Float(1) = onnx::Add(%10, %4), scope: SimpleFF1/Sequential[output_layer]/Linear[0]\n",
      "  return (%11);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer.add_graph(simpleff, input_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-19a705acd98d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimpleff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "for i, k, v in enumerate(simpleff._modules.items()):\n",
    "    print(type(v))\n",
    "    print(i)\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-eb6b05451d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for i, kv in enumerate(simpleff._modules.items()):\n",
    "    k, v = kv \n",
    "    scope = k\n",
    "    weights = v.weight()\n",
    "    print(\"{}: {}\".format(scope, list(weights)))\n",
    "    print(type(v))\n",
    "    print(i)\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SimpleFF1(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleff.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parameters(model):\n",
    "    for k, v in model.state_dict().items():\n",
    "        shape = v.shape\n",
    "        # Don't do this for single weights or biases\n",
    "        if np.any(np.array(shape) > 1):\n",
    "            mean = torch.mean(v)\n",
    "            std_dev = torch.std(v)\n",
    "            maximum = torch.max(v)\n",
    "            minimum = torch.min(v)\n",
    "            writer.add_scalars(\"layer_{}_{} \".format(k, shape), {\"mean\": mean,\n",
    "                                                                    \"std_dev\": std_dev,\n",
    "                                                                    \"max\": maximum,\n",
    "                                                                    \"min\": minimum}, batch_idx)\n",
    "            writer.add_histogram(\"layer_{}_{}\".format(k, shape), v, batch_idx)\n",
    "            \n",
    "        else:\n",
    "            writer.add_scalar(\"layer_{}_{}\".format(k, shape), v.data, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.array([1, 1]) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_all is not implemented for type torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-4383de815743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_all is not implemented for type torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "a = torch.all(torch.Tensor([1, 3 ,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters(simpleff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
